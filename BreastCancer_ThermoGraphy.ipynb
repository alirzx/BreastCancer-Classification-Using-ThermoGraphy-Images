{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2ce85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\hub\n",
      "O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TORCH_HOME\"] = r\"O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\"\n",
    "\n",
    "import torch\n",
    "print(torch.hub.get_dir())\n",
    "print(os.environ[\"TORCH_HOME\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180772bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPYTORCH_CUDA_ALLOC_CONF\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpandable_segments:True\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a803061c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Dataset Statistics:\n",
      "Total images: 175\n",
      "Class distribution:\n",
      "class_name\n",
      "Sick             70\n",
      "Unknown_class    70\n",
      "normal           35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation Dataset Statistics:\n",
      "Total images: 37\n",
      "Class distribution:\n",
      "class_name\n",
      "Unknown_class    15\n",
      "Sick             14\n",
      "normal            8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Dataset Statistics:\n",
      "Total images: 39\n",
      "Class distribution:\n",
      "class_name\n",
      "Sick             16\n",
      "Unknown_class    15\n",
      "normal            8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train Dataset Statistics:\n",
      "Total images: 175\n",
      "Class distribution:\n",
      "class_name\n",
      "Sick             70\n",
      "Unknown_class    70\n",
      "normal           35\n",
      "Name: count, dtype: int64\n",
      "Duplicate images: 0\n",
      "\n",
      "Validation Dataset Statistics:\n",
      "Total images: 37\n",
      "Class distribution:\n",
      "class_name\n",
      "Unknown_class    15\n",
      "Sick             14\n",
      "normal            8\n",
      "Name: count, dtype: int64\n",
      "Duplicate images: 0\n",
      "\n",
      "Test Dataset Statistics:\n",
      "Total images: 39\n",
      "Class distribution:\n",
      "class_name\n",
      "Sick             16\n",
      "Unknown_class    15\n",
      "normal            8\n",
      "Name: count, dtype: int64\n",
      "Duplicate images: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def create_dataframes(root_dir, train_split=0.7, val_split=0.15):\n",
    "    \"\"\"\n",
    "    Create DataFrames for train, validation, and test splits from a single directory with class folders.\n",
    "\n",
    "    Directory structure:\n",
    "    <root_dir>/\n",
    "        normal/\n",
    "        Sick/\n",
    "        Unknown_class/\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root directory of the dataset.\n",
    "        train_split (float): Proportion of data for training (default: 0.7).\n",
    "        val_split (float): Proportion of data for validation (default: 0.15).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_df, val_df, test_df, class_to_idx)\n",
    "            - train_df, val_df, test_df: DataFrames with columns \"file_path\", \"label\", \"class_name\"\n",
    "            - class_to_idx: Dict mapping class names to numeric indices\n",
    "    \"\"\"\n",
    "    valid_extensions = {'.png', '.jpg', '.jpeg', '.tif', '.bmp'}\n",
    "    data = []\n",
    "    class_names = ['normal', 'Sick', 'Unknown_class']\n",
    "    class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "    # Collect all image paths and labels\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            print(f\"Warning: {class_dir} does not exist!\")\n",
    "            continue\n",
    "\n",
    "        label = class_to_idx[class_name]\n",
    "        for file in os.listdir(class_dir):\n",
    "            if os.path.splitext(file)[1].lower() in valid_extensions:\n",
    "                image_path = os.path.join(class_dir, file)\n",
    "                data.append({\n",
    "                    \"file_path\": image_path,\n",
    "                    \"label\": label,\n",
    "                    \"class_name\": class_name\n",
    "                })\n",
    "\n",
    "    # Create a single DataFrame\n",
    "    full_df = pd.DataFrame(data)\n",
    "    \n",
    "    if full_df.empty:\n",
    "        print(\"Error: No valid images found in the dataset!\")\n",
    "        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), class_to_idx\n",
    "\n",
    "    # Split the data into train, validation, and test sets\n",
    "    train_df, temp_df = train_test_split(\n",
    "        full_df, \n",
    "        train_size=train_split, \n",
    "        stratify=full_df['label'], \n",
    "        random_state=42\n",
    "    )\n",
    "    val_size = val_split / (1 - train_split)  # Adjust validation size for remaining data\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df, \n",
    "        train_size=val_size, \n",
    "        stratify=temp_df['label'], \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Reset indices for cleanliness\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    # Print basic statistics\n",
    "    for df, split in zip([train_df, val_df, test_df], [\"Train\", \"Validation\", \"Test\"]):\n",
    "        if df.empty:\n",
    "            print(f\"Warning: No images in {split} split!\")\n",
    "        else:\n",
    "            print(f\"\\n{split} Dataset Statistics:\")\n",
    "            print(f\"Total images: {len(df)}\")\n",
    "            print(f\"Class distribution:\\n{df['class_name'].value_counts()}\")\n",
    "\n",
    "    return train_df, val_df, test_df, class_to_idx\n",
    "\n",
    "def analyze_and_plot_dataframes(train_df, val_df, test_df, class_to_idx, save_dir):\n",
    "    \"\"\"\n",
    "    Analyze and visualize each DataFrame.\n",
    "\n",
    "    Args:\n",
    "        train_df, val_df, test_df (pd.DataFrame): DataFrames for each split.\n",
    "        class_to_idx (dict): Mapping of class names to indices.\n",
    "        save_dir (str): Directory to save plots.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Basic statistics and duplicates\n",
    "    for df, split in zip([train_df, val_df, test_df], [\"Train\", \"Validation\", \"Test\"]):\n",
    "        if not df.empty:\n",
    "            print(f\"\\n{split} Dataset Statistics:\")\n",
    "            print(f\"Total images: {len(df)}\")\n",
    "            print(f\"Class distribution:\\n{df['class_name'].value_counts()}\")\n",
    "            print(f\"Duplicate images: {df['file_path'].duplicated().sum()}\")\n",
    "\n",
    "    # Dynamic color palette for classes\n",
    "    class_names = sorted(class_to_idx.keys())\n",
    "    colors = sns.color_palette(\"husl\", len(class_names))\n",
    "    color_map = {idx: colors[i] for i, idx in enumerate(class_to_idx.values())}\n",
    "\n",
    "    # Plot class distribution for each split\n",
    "    for df, split in zip([train_df, val_df, test_df], [\"Train\", \"Validation\", \"Test\"]):\n",
    "        if df.empty:\n",
    "            continue\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        counts = df['label'].value_counts().sort_index()\n",
    "        bars = plt.bar(counts.index, counts.values, color=[color_map[i] for i in counts.index])\n",
    "        \n",
    "        plt.ylim(0, counts.max() + counts.max() * 0.1)\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.annotate(f'{int(height)}',\n",
    "                         xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                         xytext=(0, 5),\n",
    "                         textcoords='offset points',\n",
    "                         ha='center', va='bottom')\n",
    "        \n",
    "        plt.xlabel('Class')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title(f'Class Distribution in {split} Set')\n",
    "        plt.xticks(counts.index, [class_names[i] for i in counts.index], rotation=45)\n",
    "        plt.grid(axis='y', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, f\"{split.lower()}_class_distribution.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    # Plot random samples (up to 10 per class) for each split\n",
    "    for df, split in zip([train_df, val_df, test_df], [\"Train\", \"Validation\", \"Test\"]):\n",
    "        if df.empty:\n",
    "            continue\n",
    "        classes = sorted(df['class_name'].unique())\n",
    "        samples_per_class = min(10, df['class_name'].value_counts().min())\n",
    "        \n",
    "        # Calculate grid size\n",
    "        n_cols = min(5, samples_per_class)\n",
    "        n_rows = (samples_per_class + n_cols - 1) // n_cols * len(classes)\n",
    "        \n",
    "        plt.figure(figsize=(n_cols * 4, n_rows * 4))\n",
    "        plot_idx = 1\n",
    "        \n",
    "        for class_name in classes:\n",
    "            class_images = df[df['class_name'] == class_name]['file_path'].values\n",
    "            if len(class_images) == 0:\n",
    "                continue\n",
    "            samples = np.random.choice(class_images, min(samples_per_class, len(class_images)), replace=False)\n",
    "            \n",
    "            for img_path in samples:\n",
    "                plt.subplot(n_rows, n_cols, plot_idx)\n",
    "                img = Image.open(img_path)\n",
    "                # Convert grayscale to RGB if necessary\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                plt.imshow(img)\n",
    "                plt.title(class_name, fontsize=12)\n",
    "                plt.axis('off')\n",
    "                plot_idx += 1\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, f\"{split.lower()}_random_samples.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    root_dir = r\"O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\archive\\BCD_Dataset\"\n",
    "    save_dir = r\"O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\"\n",
    "    train_df, val_df, test_df, class_to_idx = create_dataframes(root_dir)\n",
    "    analyze_and_plot_dataframes(train_df, val_df, test_df, class_to_idx, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba0e69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Dataset Statistics:\n",
      "Total images: 175\n",
      "Class distribution:\n",
      "class_name\n",
      "Sick             70\n",
      "Unknown_class    70\n",
      "normal           35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation Dataset Statistics:\n",
      "Total images: 37\n",
      "Class distribution:\n",
      "class_name\n",
      "Unknown_class    15\n",
      "Sick             14\n",
      "normal            8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Dataset Statistics:\n",
      "Total images: 39\n",
      "Class distribution:\n",
      "class_name\n",
      "Sick             16\n",
      "Unknown_class    15\n",
      "normal            8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "New class distribution after oversampling:\n",
      "label\n",
      "1    70\n",
      "0    70\n",
      "2    70\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Pie Chart 1: Dataset Split Distribution\n",
    "def plot_dataset_split_pie(train_df, val_df, test_df, save_dir=\"data_analysis\"):\n",
    "    \"\"\"\n",
    "    Plot a pie chart showing the distribution of samples across train, val, and test splits.\n",
    "\n",
    "    Args:\n",
    "        train_df, val_df, test_df (pd.DataFrame): DataFrames for each split.\n",
    "        save_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    sizes = [len(train_df), len(val_df), len(test_df)]\n",
    "    labels = ['Training', 'Validation', 'Test']\n",
    "    total = sum(sizes)\n",
    "    colors = sns.color_palette(\"husl\", 3)  # Consistent palette for 3 classes\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        sizes,\n",
    "        labels=labels,\n",
    "        autopct=lambda pct: f\"{pct:.1f}%\\n({int(pct/100.*total)})\",\n",
    "        startangle=140,\n",
    "        colors=colors,\n",
    "        shadow=True,\n",
    "        wedgeprops={'edgecolor': 'white', 'linewidth': 1}\n",
    "    )\n",
    "\n",
    "    for text in texts:\n",
    "        text.set_fontsize(14)\n",
    "        text.set_fontweight('bold')\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_fontsize(12)\n",
    "\n",
    "    ax.set_title(\"Breast Cancer Thermography Dataset Split Distribution\", fontsize=16, fontweight='bold')\n",
    "    plt.text(0, -1.3, f\"Total Samples: {total}\", fontsize=12, ha='center', style='italic')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(save_dir, \"dataset_split_pie.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Pie Chart 2: Test Set Class Distribution\n",
    "def plot_test_class_pie(test_df, class_to_idx, save_dir=\"data_analysis\"):\n",
    "    \"\"\"\n",
    "    Plot a pie chart showing the class distribution in the test set.\n",
    "\n",
    "    Args:\n",
    "        test_df (pd.DataFrame): Test DataFrame with 'label' and 'class_name' columns.\n",
    "        class_to_idx (dict): Mapping of class names to numeric indices.\n",
    "        save_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    if test_df.empty:\n",
    "        print(\"Warning: Test DataFrame is empty, skipping test class pie chart.\")\n",
    "        return\n",
    "\n",
    "    class_counts = test_df['label'].value_counts().sort_index()\n",
    "    sizes = class_counts.values\n",
    "    labels = [list(class_to_idx.keys())[list(class_to_idx.values()).index(i)] for i in class_counts.index]\n",
    "    total = sum(sizes)\n",
    "    colors = sns.color_palette(\"husl\", len(labels))  # Consistent palette\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        sizes,\n",
    "        labels=labels,\n",
    "        autopct=lambda pct: f\"{pct:.1f}%\\n({int(pct/100.*total)})\",\n",
    "        startangle=140,\n",
    "        colors=colors,\n",
    "        shadow=True,\n",
    "        wedgeprops={'edgecolor': 'white', 'linewidth': 1}\n",
    "    )\n",
    "\n",
    "    for text in texts:\n",
    "        text.set_fontsize(14)\n",
    "        text.set_fontweight('bold')\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_fontsize(12)\n",
    "\n",
    "    ax.set_title(\"Test Set Class Distribution (Normal, Sick, Unknown)\", fontsize=16, fontweight='bold')\n",
    "    plt.text(0, -1.3, f\"Total Test Samples: {total}\", fontsize=12, ha='center', style='italic')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(save_dir, \"test_class_pie.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Pie Chart 3: Balanced Training Set Class Distribution\n",
    "def plot_train_balanced_class_pie(train_df_balanced, class_to_idx, save_dir=\"data_analysis\"):\n",
    "    \"\"\"\n",
    "    Plot a pie chart showing the class distribution in the balanced training set.\n",
    "\n",
    "    Args:\n",
    "        train_df_balanced (pd.DataFrame): Balanced training DataFrame with 'label' and 'class_name' columns.\n",
    "        class_to_idx (dict): Mapping of class names to numeric indices.\n",
    "        save_dir (str): Directory to save the plot.\n",
    "    \"\"\"\n",
    "    if train_df_balanced.empty:\n",
    "        print(\"Warning: Balanced Train DataFrame is empty, skipping balanced train class pie chart.\")\n",
    "        return\n",
    "\n",
    "    class_counts = train_df_balanced['label'].value_counts().sort_index()\n",
    "    sizes = class_counts.values\n",
    "    labels = [list(class_to_idx.keys())[list(class_to_idx.values()).index(i)] for i in class_counts.index]\n",
    "    total = sum(sizes)\n",
    "    colors = sns.color_palette(\"husl\", len(labels))  # Consistent palette\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        sizes,\n",
    "        labels=labels,\n",
    "        autopct=lambda pct: f\"{pct:.1f}%\\n({int(pct/100.*total)})\",\n",
    "        startangle=140,\n",
    "        colors=colors,\n",
    "        shadow=True,\n",
    "        wedgeprops={'edgecolor': 'white', 'linewidth': 1}\n",
    "    )\n",
    "\n",
    "    for text in texts:\n",
    "        text.set_fontsize(14)\n",
    "        text.set_fontweight('bold')\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_fontsize(12)\n",
    "\n",
    "    ax.set_title(\"Balanced Training Set Class Distribution (Normal, Sick, Unknown)\", fontsize=16, fontweight='bold')\n",
    "    plt.text(0, -1.3, f\"Total Balanced Train Samples: {total}\", fontsize=12, ha='center', style='italic')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(save_dir, \"train_balanced_class_pie.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Resample train_df to balance classes\n",
    "def resample_train_df(train_df, class_to_idx, save_dir=\"data_analysis\"):\n",
    "    \"\"\"\n",
    "    Resample the training DataFrame to balance classes by oversampling minority classes.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training DataFrame with 'file_path', 'label', 'class_name' columns.\n",
    "        class_to_idx (dict): Mapping of class names to numeric indices.\n",
    "        save_dir (str): Directory to save the distribution plot.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Balanced training DataFrame.\n",
    "    \"\"\"\n",
    "    if train_df.empty:\n",
    "        print(\"Error: Training DataFrame is empty, cannot balance.\")\n",
    "        return train_df\n",
    "\n",
    "    # Get class counts\n",
    "    class_counts = train_df['label'].value_counts()\n",
    "    majority_count = class_counts.max()\n",
    "    majority_label = class_counts.idxmax()\n",
    "\n",
    "    # Separate DataFrames for each class\n",
    "    dfs_by_class = [train_df[train_df['label'] == label] for label in class_counts.index]\n",
    "\n",
    "    # Oversample minority classes to match majority\n",
    "    balanced_dfs = []\n",
    "    for df_class, label in zip(dfs_by_class, class_counts.index):\n",
    "        if label == majority_label:\n",
    "            balanced_dfs.append(df_class)\n",
    "        else:\n",
    "            df_oversampled = resample(\n",
    "                df_class,\n",
    "                replace=True,\n",
    "                n_samples=majority_count,\n",
    "                random_state=42\n",
    "            )\n",
    "            balanced_dfs.append(df_oversampled)\n",
    "\n",
    "    # Combine all classes\n",
    "    train_df_balanced = pd.concat(balanced_dfs)\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    train_df_balanced = train_df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Print new class distribution\n",
    "    print(\"\\nNew class distribution after oversampling:\")\n",
    "    print(train_df_balanced['label'].value_counts())\n",
    "\n",
    "    # Visualize new class distribution (bar plot)\n",
    "    class_names = sorted(class_to_idx, key=class_to_idx.get)  # Sort by index\n",
    "    colors = sns.color_palette(\"husl\", len(class_names))\n",
    "    color_map = {i: colors[i] for i in range(len(class_names))}\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    counts = train_df_balanced['label'].value_counts().sort_index()\n",
    "    bars = plt.bar(counts.index, counts.values, color=[color_map[i] for i in counts.index])\n",
    "\n",
    "    plt.ylim(0, counts.max() + counts.max() * 0.1)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{int(height)}',\n",
    "                     xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                     xytext=(0, 5),\n",
    "                     textcoords='offset points',\n",
    "                     ha='center', va='bottom')\n",
    "\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Class Distribution in Balanced Training Set (Normal, Sick, Unknown)')\n",
    "    plt.xticks(counts.index, [class_names[i] for i in counts.index], rotation=45)\n",
    "    plt.grid(axis='y', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(save_dir, \"train_balanced_class_bar.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot pie chart for balanced training set\n",
    "    plot_train_balanced_class_pie(train_df_balanced, class_to_idx, save_dir)\n",
    "\n",
    "    return train_df_balanced\n",
    "\n",
    "# Example usage (assuming train_df, val_df, test_df, class_to_idx are from previous code)\n",
    "if __name__ == \"__main__\":\n",
    "    # Placeholder for DataFrames (replace with actual DataFrames from previous code)\n",
    "    root_dir = r\"O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\archive\\BCD_Dataset\"\n",
    "    save_dir = r\"O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\"\n",
    "    \n",
    "    # Assuming create_dataframes is defined as in the previous artifact\n",
    "    \n",
    "    train_df, val_df, test_df, class_to_idx = create_dataframes(root_dir)\n",
    "    \n",
    "    # Plot dataset split and test class distribution\n",
    "    plot_dataset_split_pie(train_df, val_df, test_df, save_dir)\n",
    "    plot_test_class_pie(test_df, class_to_idx, save_dir)\n",
    "    \n",
    "    # Balance the training set and visualize\n",
    "    train_df_balanced = resample_train_df(train_df, class_to_idx, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c87d1f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 00:12:00,659 - INFO - Using device: cuda\n",
      "2025-05-30 00:12:00,820 - INFO - Filtered out 0 invalid rows\n",
      "2025-05-30 00:12:00,821 - INFO - Dataset size after filtering: 210\n",
      "2025-05-30 00:12:00,822 - INFO - Classes: ['Sick', 'Unknown_class', 'normal']\n",
      "2025-05-30 00:12:00,823 - INFO - Class to index: {'Sick': 0, 'Unknown_class': 1, 'normal': 2}\n",
      "2025-05-30 00:12:00,826 - INFO - Class distribution:\n",
      "class_name\n",
      "Sick             70\n",
      "normal           70\n",
      "Unknown_class    70\n",
      "Name: count, dtype: int64\n",
      "2025-05-30 00:12:00,854 - INFO - Filtered out 0 invalid rows\n",
      "2025-05-30 00:12:00,854 - INFO - Dataset size after filtering: 37\n",
      "2025-05-30 00:12:00,854 - INFO - Classes: ['Sick', 'Unknown_class', 'normal']\n",
      "2025-05-30 00:12:00,854 - INFO - Class to index: {'Sick': 0, 'Unknown_class': 1, 'normal': 2}\n",
      "2025-05-30 00:12:00,854 - INFO - Class distribution:\n",
      "class_name\n",
      "Unknown_class    15\n",
      "Sick             14\n",
      "normal            8\n",
      "Name: count, dtype: int64\n",
      "2025-05-30 00:12:00,900 - INFO - Filtered out 0 invalid rows\n",
      "2025-05-30 00:12:00,902 - INFO - Dataset size after filtering: 39\n",
      "2025-05-30 00:12:00,903 - INFO - Classes: ['Sick', 'Unknown_class', 'normal']\n",
      "2025-05-30 00:12:00,904 - INFO - Class to index: {'Sick': 0, 'Unknown_class': 1, 'normal': 2}\n",
      "2025-05-30 00:12:00,906 - INFO - Class distribution:\n",
      "class_name\n",
      "Sick             16\n",
      "Unknown_class    15\n",
      "normal            8\n",
      "Name: count, dtype: int64\n",
      "2025-05-30 00:12:00,907 - INFO - Number of classes: 3\n",
      "2025-05-30 00:12:00,908 - INFO - Classes: ['Sick', 'Unknown_class', 'normal']\n",
      "2025-05-30 00:12:00,910 - INFO - Training dataset size: 210\n",
      "2025-05-30 00:12:00,911 - INFO - Validation dataset size: 37\n",
      "2025-05-30 00:12:00,912 - INFO - Test dataset size: 39\n",
      "2025-05-30 00:12:00,913 - INFO - Batch size: 64\n",
      "2025-05-30 00:12:01,231 - INFO - Class weights: tensor([1., 1., 1.], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os\n",
    "import gc\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Handle truncated/corrupted images\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# Define preprocessing transforms with albumentations\n",
    "def get_transforms(split, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "    \"\"\"\n",
    "    Define Albumentations transforms for train/val/test splits, tailored for thermography images.\n",
    "\n",
    "    Args:\n",
    "        split (str): Dataset split ('train', 'val', or 'test').\n",
    "        mean (tuple): Mean values for normalization (default: ImageNet means).\n",
    "        std (tuple): Standard deviation values for normalization (default: ImageNet stds).\n",
    "\n",
    "    Returns:\n",
    "        A.Compose: Albumentations transformation pipeline.\n",
    "    \"\"\"\n",
    "    if split == \"train\":\n",
    "        return A.Compose([\n",
    "            A.Resize(224, 224, always_apply=True),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Rotate(limit=30, p=0.5),  # Reduced rotation for thermography images\n",
    "            A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.0, p=0.5),  # No hue shift for thermal images\n",
    "            A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=0.5),  # Enhance contrast for thermography\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n",
    "            A.GaussianBlur(blur_limit=(3, 5), p=0.3),  # Reduced blur intensity\n",
    "            A.Normalize(mean=mean, std=std),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(224, 224, always_apply=True),\n",
    "            A.Normalize(mean=mean, std=std),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "# Wrapper to use albumentations with PyTorch\n",
    "class AlbumentationsTransform:\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        augmented = self.transform(image=img)\n",
    "        return augmented['image']\n",
    "\n",
    "# Custom Dataset for DataFrame\n",
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize dataset from DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame with 'file_path', 'label', 'class_name' columns.\n",
    "            transform: Albumentations transformation pipeline.\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(self.df['class_name'].unique())\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.df = self._validate_and_filter_dataset()\n",
    "        unique_labels = sorted(self.df['label'].unique())\n",
    "        expected_labels = list(range(len(self.classes)))\n",
    "        if sorted(unique_labels) != expected_labels:\n",
    "            logger.error(f\"Label mismatch: Expected labels {expected_labels}, found {unique_labels}\")\n",
    "            raise ValueError(f\"Label mismatch: Expected {expected_labels}, found {unique_labels}\")\n",
    "        logger.info(f\"Dataset size after filtering: {len(self.df)}\")\n",
    "        logger.info(f\"Classes: {self.classes}\")\n",
    "        logger.info(f\"Class to index: {self.class_to_idx}\")\n",
    "        logger.info(f\"Class distribution:\\n{self.df['class_name'].value_counts()}\")\n",
    "\n",
    "    def _validate_and_filter_dataset(self):\n",
    "        \"\"\"\n",
    "        Filter out invalid images or labels from the dataset.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Filtered DataFrame.\n",
    "        \"\"\"\n",
    "        valid_rows = []\n",
    "        for idx in range(len(self.df)):\n",
    "            row = self.df.iloc[idx]\n",
    "            img_path = row['file_path']\n",
    "            label = row['label']\n",
    "            if not os.path.isfile(img_path):\n",
    "                logger.warning(f\"Invalid file path at index {idx}: {img_path}\")\n",
    "                continue\n",
    "            if not isinstance(label, (int, np.integer)) or label not in range(len(self.classes)):\n",
    "                logger.warning(f\"Invalid label at index {idx}: {label}\")\n",
    "                continue\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img.close()\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Corrupted image at index {idx}: {img_path}, error: {e}\")\n",
    "                continue\n",
    "            valid_rows.append(idx)\n",
    "        if not valid_rows:\n",
    "            raise ValueError(\"No valid items in dataset after filtering\")\n",
    "        filtered_df = self.df.iloc[valid_rows].reset_index(drop=True)\n",
    "        logger.info(f\"Filtered out {len(self.df) - len(filtered_df)} invalid rows\")\n",
    "        return filtered_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['file_path']\n",
    "        label = row['label']\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')  # Ensure RGB for thermography images\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading image {img_path}: {e}\")\n",
    "            return None\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        if label_tensor.numel() != 1:\n",
    "            logger.error(f\"Label at index {idx} is not scalar: {label_tensor}\")\n",
    "            return None\n",
    "        logger.debug(f\"Item {idx}: label {label} -> tensor {label_tensor}\")\n",
    "        return img, label_tensor\n",
    "\n",
    "# Custom Dataset Wrapper\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        if item is None:\n",
    "            logger.warning(f\"Skipping None item at index {idx}\")\n",
    "            raise IndexError(\"Invalid item in dataset\")\n",
    "        return item\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.dataset, name)\n",
    "\n",
    "# Create Data Loaders\n",
    "def create_data_loaders(train_df, val_df, test_df, batch_size=32):\n",
    "    \"\"\"\n",
    "    Create DataLoaders for train, validation, and test datasets.\n",
    "\n",
    "    Args:\n",
    "        train_df, val_df, test_df (pd.DataFrame): DataFrames for each split.\n",
    "        batch_size (int): Batch size for DataLoaders.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (train_loader, val_loader, test_loader, num_classes)\n",
    "    \"\"\"\n",
    "    # Define transforms\n",
    "    train_transform = AlbumentationsTransform(get_transforms(\"train\"))\n",
    "    val_test_transform = AlbumentationsTransform(get_transforms(\"val\"))\n",
    "\n",
    "    # Create datasets\n",
    "    try:\n",
    "        train_dataset = DataFrameDataset(train_df, transform=train_transform)\n",
    "        val_dataset = DataFrameDataset(val_df, transform=val_test_transform)\n",
    "        test_dataset = DataFrameDataset(test_df, transform=val_test_transform)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating datasets: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Wrap datasets\n",
    "    train_dataset_custom = CustomDataset(train_dataset)\n",
    "    val_dataset_custom = CustomDataset(val_dataset)\n",
    "    test_dataset_custom = CustomDataset(test_dataset)\n",
    "\n",
    "    num_classes = len(train_dataset.classes)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset_custom,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=0,  # Set to 0 for Windows compatibility\n",
    "        pin_memory=True,\n",
    "        drop_last=True  # Drop incomplete batches to avoid issues\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset_custom,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset_custom,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Dataset summary\n",
    "    logger.info(f\"Number of classes: {num_classes}\")\n",
    "    logger.info(f\"Classes: {train_dataset.classes}\")\n",
    "    logger.info(f\"Training dataset size: {len(train_loader.dataset)}\")\n",
    "    logger.info(f\"Validation dataset size: {len(val_loader.dataset)}\")\n",
    "    logger.info(f\"Test dataset size: {len(test_loader.dataset)}\")\n",
    "    logger.info(f\"Batch size: {batch_size}\")\n",
    "\n",
    "    return train_loader, val_loader, test_loader, num_classes\n",
    "\n",
    "# Compute class weights for imbalanced dataset\n",
    "def compute_class_weights(train_df):\n",
    "    \"\"\"\n",
    "    Compute class weights for training based on class distribution.\n",
    "\n",
    "    Args:\n",
    "        train_df (pd.DataFrame): Training DataFrame with 'label' column.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Class weights for loss function.\n",
    "    \"\"\"\n",
    "    if train_df.empty:\n",
    "        logger.error(\"Training DataFrame is empty, cannot compute class weights.\")\n",
    "        return None\n",
    "    labels = train_df['label'].values\n",
    "    unique_labels = np.unique(labels)\n",
    "    class_weights = compute_class_weight('balanced', classes=unique_labels, y=labels)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    logger.info(f\"Class weights: {class_weights}\")\n",
    "    return class_weights\n",
    "\n",
    "\n",
    "# root_dir = r\"O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\archive\\BCD_Dataset\"\n",
    "# save_dir = r\"O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\"\n",
    "\n",
    "# Create DataFrames\n",
    "# train_df, val_df, test_df, class_to_idx = create_dataframes(root_dir)\n",
    "\n",
    "# # Balance training DataFrame\n",
    "# train_df_balanced = resample_train_df(train_df, class_to_idx, save_dir)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader, val_loader, test_loader, num_classes = create_data_loaders(\n",
    "    train_df_balanced, val_df, test_df, batch_size\n",
    ")\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weights(train_df_balanced)\n",
    "\n",
    "# Memory optimization\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97da458a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 00:12:01,501 - INFO - Using device: cuda\n",
      "2025-05-30 00:12:01,938 - INFO - ✅ Batch 1 Loaded in 0.0000 sec\n",
      "2025-05-30 00:12:01,938 - INFO - Batch 1 inputs shape: torch.Size([64, 3, 224, 224])\n",
      "2025-05-30 00:12:01,953 - INFO - Batch 1 labels: tensor([0, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1, 2, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 2,\n",
      "        1, 0, 2, 1, 0, 1, 0, 2, 2, 0, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 0, 1, 1,\n",
      "        2, 1, 0, 2, 2, 1, 1, 0, 2, 2, 0, 0, 0, 0, 2, 0], device='cuda:0')\n",
      "2025-05-30 00:12:02,208 - INFO - ✅ Batch 2 Loaded in 0.0000 sec\n",
      "2025-05-30 00:12:02,208 - INFO - Batch 2 inputs shape: torch.Size([64, 3, 224, 224])\n",
      "2025-05-30 00:12:02,223 - INFO - Batch 2 labels: tensor([2, 1, 1, 1, 0, 1, 0, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 0, 0,\n",
      "        1, 2, 1, 2, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 1, 0, 2, 2, 0, 2,\n",
      "        0, 2, 2, 0, 0, 1, 1, 2, 1, 1, 2, 0, 2, 0, 2, 0], device='cuda:0')\n",
      "2025-05-30 00:12:02,463 - INFO - ✅ Batch 3 Loaded in 0.0000 sec\n",
      "2025-05-30 00:12:02,463 - INFO - Batch 3 inputs shape: torch.Size([64, 3, 224, 224])\n",
      "2025-05-30 00:12:02,463 - INFO - Batch 3 labels: tensor([1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 2, 1, 1, 2, 0, 0, 2, 1, 1, 1, 0, 2, 2, 0,\n",
      "        2, 2, 0, 0, 2, 2, 0, 1, 2, 0, 1, 2, 0, 2, 2, 1, 2, 2, 0, 0, 0, 1, 1, 0,\n",
      "        1, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 1, 1, 2, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Select CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# Check batch loading time\n",
    "for i, (inputs, labels) in enumerate(train_loader):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Skip invalid batches\n",
    "    if inputs is None or labels is None:\n",
    "        logger.warning(f\"Skipping empty batch {i+1}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Validate inputs\n",
    "        if not isinstance(inputs, torch.Tensor):\n",
    "            logger.error(f\"Batch {i+1} inputs is not a tensor: {type(inputs)}\")\n",
    "            continue\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # Handle labels (tensor or tuple)\n",
    "        if isinstance(labels, tuple):\n",
    "            labels1, labels2, lam = labels\n",
    "            if not isinstance(labels1, torch.Tensor) or not isinstance(labels2, torch.Tensor):\n",
    "                logger.error(f\"Batch {i+1} labels tuple contains non-tensor: {type(labels1)}, {type(labels2)}\")\n",
    "                continue\n",
    "            labels = (labels1.to(device), labels2.to(device), lam)\n",
    "        else:\n",
    "            if not isinstance(labels, torch.Tensor):\n",
    "                logger.error(f\"Batch {i+1} labels is not a tensor: {type(labels)}\")\n",
    "                continue\n",
    "            labels = labels.to(device)\n",
    "\n",
    "        batch_time = time.time() - start_time\n",
    "        logger.info(f\"✅ Batch {i+1} Loaded in {batch_time:.4f} sec\")\n",
    "        logger.info(f\"Batch {i+1} inputs shape: {inputs.shape}\")\n",
    "        logger.info(f\"Batch {i+1} labels: {labels}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing batch {i+1}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if i == 3:\n",
    "        break\n",
    "\n",
    "# Memory cleanup\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1624c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.amp import GradScaler, autocast  # Updated AMP import\n",
    "from torchvision import models\n",
    "from torchvision.models import (\n",
    "    ResNeXt50_32X4D_Weights, DenseNet201_Weights, EfficientNet_B0_Weights,\n",
    "    ResNet18_Weights, ResNet50_Weights, ResNeXt101_32X8D_Weights\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0, save_dir=None):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.best_epoch = 0\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "    def __call__(self, val_loss, epoch, model_weights, model_name_prefix):\n",
    "        if val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "            self.save_best_weights(model_weights, model_name_prefix)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    logger.info(f\"Early stopping triggered after {self.counter} epochs of no improvement.\")\n",
    "\n",
    "    def save_best_weights(self, model_weights, model_name_prefix):\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        model_name = os.path.join(self.save_dir, f\"{model_name_prefix}_epoch_{self.best_epoch + 1}.pth\")\n",
    "        torch.save(model_weights, model_name)\n",
    "        if self.verbose:\n",
    "            logger.info(f\"✅ Best model weights saved to {model_name}\")\n",
    "\n",
    "# Custom Classifier\n",
    "class CustomClassifier(nn.Module):\n",
    "    def __init__(self, in_features, num_classes):\n",
    "        super(CustomClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Supervised Contrastive Loss\n",
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        device = features.device\n",
    "        batch_size = features.size(0)\n",
    "        if batch_size < 2:\n",
    "            return torch.tensor(0.0, device=device)\n",
    "\n",
    "        features = torch.nn.functional.normalize(features, dim=1)\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "        labels = labels.contiguous().view(-1, 1)\n",
    "        mask = torch.eq(labels, labels.T).float().to(device)\n",
    "        exp_sim = torch.exp(similarity_matrix)\n",
    "        pos_mask = mask - torch.eye(batch_size, device=device)\n",
    "        pos_sum = (exp_sim * pos_mask).sum(dim=1, keepdim=True)\n",
    "        neg_sum = (exp_sim * (1 - pos_mask)).sum(dim=1, keepdim=True)\n",
    "        pos_sum = torch.where(pos_sum == 0, torch.ones_like(pos_sum), pos_sum)\n",
    "        loss = -torch.log(pos_sum / (pos_sum + neg_sum + 1e-6))\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "# Contrastive Model\n",
    "class ContrastiveModel(nn.Module):\n",
    "    def __init__(self, base_model, num_classes, feature_dim):\n",
    "        super(ContrastiveModel, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feature_dim = feature_dim\n",
    "        self.backbone = base_model\n",
    "\n",
    "        if hasattr(self.backbone, 'fc'):\n",
    "            self.classifier_attr = 'fc'\n",
    "        elif hasattr(self.backbone, 'classifier'):\n",
    "            self.classifier_attr = 'classifier'\n",
    "        else:\n",
    "            raise ValueError(\"Backbone has neither 'fc' nor 'classifier' attribute\")\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*list(self.backbone.children())[:-1])\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        classifier = getattr(self.backbone, self.classifier_attr)\n",
    "        logits = classifier(features)\n",
    "        proj = self.projection_head(features)\n",
    "        return logits, proj\n",
    "\n",
    "# Get Model\n",
    "def get_model(model_name, num_classes, device):\n",
    "    logger.info(f\"Loading model: {model_name} with {num_classes} classes on {device}\")\n",
    "\n",
    "    model_configs = {\n",
    "        \"resnext50\": (models.resnext50_32x4d, ResNeXt50_32X4D_Weights.DEFAULT, 2048),\n",
    "        \"densenet201\": (models.densenet201, DenseNet201_Weights.DEFAULT, 1920),\n",
    "        \"efficientnet_b0\": (models.efficientnet_b0, EfficientNet_B0_Weights.DEFAULT, 1280),\n",
    "        \"resnet18\": (models.resnet18, ResNet18_Weights.DEFAULT, 512),\n",
    "        \"resnet50\": (models.resnet50, ResNet50_Weights.DEFAULT, 2048),\n",
    "        \"resnext101\": (models.resnext101_32x8d, ResNeXt101_32X8D_Weights.DEFAULT, 2048)\n",
    "    }\n",
    "\n",
    "    if model_name not in model_configs:\n",
    "        raise ValueError(f\"Model {model_name} not supported.\")\n",
    "\n",
    "    model_fn, weights, in_features = model_configs[model_name]\n",
    "    base_model = model_fn(weights=weights)\n",
    "\n",
    "    for param in base_model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    if hasattr(base_model, 'fc'):\n",
    "        classifier_attr = 'fc'\n",
    "    elif hasattr(base_model, 'classifier'):\n",
    "        classifier_attr = 'classifier'\n",
    "    else:\n",
    "        raise ValueError(\"Cannot find classifier layer\")\n",
    "\n",
    "    custom_classifier = CustomClassifier(in_features, num_classes)\n",
    "    setattr(base_model, classifier_attr, custom_classifier)\n",
    "\n",
    "    try:\n",
    "        model = ContrastiveModel(base_model, num_classes, feature_dim=in_features)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize ContrastiveModel: {e}\")\n",
    "        raise\n",
    "\n",
    "    logger.info(f\"Model {model_name} loaded with {in_features} input features to classifier\")\n",
    "    return model.to(device)\n",
    "\n",
    "# Compute Metrics\n",
    "def compute_metrics(model, data_loader, device, epoch, split_name, save_dir, class_names):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            if inputs is None or labels is None:\n",
    "                logger.debug(f\"Skipping invalid {split_name} batch\")\n",
    "                continue\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            with autocast('cuda'):  # Updated AMP\n",
    "                logits, _ = model(inputs)\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{split_name.capitalize()} Confusion Matrix - Epoch {epoch}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(save_dir, f\"{split_name}_confusion_matrix_epoch_{epoch}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
    "    logger.info(f\"\\n{split_name.capitalize()} Classification Report - Epoch {epoch}:\\n{report}\")\n",
    "    with open(os.path.join(save_dir, f\"{split_name}_classification_report_epoch_{epoch}.txt\"), 'w') as f:\n",
    "        f.write(report)\n",
    "\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(all_labels, all_probs, multi_class='ovr')\n",
    "        logger.info(f\"{split_name.capitalize()} ROC AUC: {roc_auc:.4f}\")\n",
    "        with open(os.path.join(save_dir, f\"{split_name}_roc_auc_epoch_{epoch}.txt\"), 'w') as f:\n",
    "            f.write(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    except ValueError as e:\n",
    "        logger.warning(f\"ROC AUC computation failed for {split_name}: {e}\")\n",
    "\n",
    "# Plot Loss and Accuracy\n",
    "def plot_loss_accuracy(train_losses, valid_losses, train_accuracies, valid_accuracies, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_losses, 'b-', label='Training Loss')\n",
    "    plt.plot(epochs, valid_losses, 'r-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, \"loss_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_accuracies, 'b-', label='Training Accuracy')\n",
    "    plt.plot(epochs, valid_accuracies, 'r-', label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_dir, \"accuracy_curve.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Train and Validate\n",
    "def train_and_validate(model, train_loader, val_loader, optimizer, scheduler, \n",
    "                       model_name_prefix, class_weights, epochs=25, device=None, \n",
    "                       early_stopping=None, save_dir=r\"O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\", \n",
    "                       accum_steps=4, class_names=['normal', 'Sick', 'Unknown_class']):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    use_amp = device.type == 'cuda'\n",
    "    logger.info(f\"Using mixed precision training: {use_amp}\")\n",
    "\n",
    "    ce_criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    supcon_criterion = SupConLoss(temperature=0.07)\n",
    "    lambda_supcon = 0.3\n",
    "\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accuracies = []\n",
    "    valid_accuracies = []\n",
    "    scaler = GradScaler('cuda') if use_amp else None  # Updated AMP\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        logger.info(f'Epoch {epoch + 1}/{epochs}')\n",
    "        logger.info('-' * 50)\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            if inputs is None or labels is None:\n",
    "                logger.debug(\"Skipping invalid training batch\")\n",
    "                continue\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            if use_amp:\n",
    "                with autocast('cuda', dtype=torch.float16):  # Updated AMP\n",
    "                    logits, proj = model(inputs)\n",
    "                    ce_loss = ce_criterion(logits, labels)\n",
    "                    supcon_loss = supcon_criterion(proj, labels)\n",
    "                    total_loss = (ce_loss + lambda_supcon * supcon_loss) / accum_steps\n",
    "            else:\n",
    "                logits, proj = model(inputs)\n",
    "                ce_loss = ce_criterion(logits, labels)\n",
    "                supcon_loss = supcon_criterion(proj, labels)\n",
    "                total_loss = (ce_loss + lambda_supcon * supcon_loss) / accum_steps\n",
    "\n",
    "            if use_amp:\n",
    "                scaler.scale(total_loss).backward()\n",
    "                if (batch_idx + 1) % accum_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "            else:\n",
    "                total_loss.backward()\n",
    "                if (batch_idx + 1) % accum_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "            running_loss += total_loss.item() * inputs.size(0) * accum_steps\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct_preds / total_preds\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "        logger.info(f'Training Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                if inputs is None or labels is None:\n",
    "                    logger.debug(\"Skipping invalid validation batch\")\n",
    "                    continue\n",
    "\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                if use_amp:\n",
    "                    with autocast('cuda', dtype=torch.float16):  # Updated AMP\n",
    "                        logits, _ = model(inputs)\n",
    "                        loss = ce_criterion(logits, labels)\n",
    "                else:\n",
    "                    logits, _ = model(inputs)\n",
    "                    loss = ce_criterion(logits, labels)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(logits, 1)\n",
    "                correct_preds += (preds == labels).sum().item()\n",
    "                total_preds += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(val_loader.dataset)\n",
    "        epoch_acc = correct_preds / total_preds\n",
    "        valid_losses.append(epoch_loss)\n",
    "        valid_accuracies.append(epoch_acc)\n",
    "        logger.info(f'Validation Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "        if early_stopping:\n",
    "            early_stopping(epoch_loss, epoch, model.state_dict(), model_name_prefix)\n",
    "            if early_stopping.early_stop:\n",
    "                logger.info(f\"🚨 Early stopping triggered at epoch {epoch+1}.\")\n",
    "                break\n",
    "\n",
    "        if epoch % 5 == 0 or (early_stopping and early_stopping.early_stop):\n",
    "            compute_metrics(model, val_loader, device, epoch + 1, \"val\", save_dir, class_names)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if early_stopping and early_stopping.best_epoch is not None:\n",
    "        logger.info(f\"Loading best model weights from epoch {early_stopping.best_epoch + 1}\")\n",
    "        best_model_path = os.path.join(save_dir, f\"{model_name_prefix}_epoch_{early_stopping.best_epoch + 1}.pth\")\n",
    "        model.load_state_dict(torch.load(best_model_path))\n",
    "    else:\n",
    "        logger.info(\"No early stopping triggered. Keeping final epoch weights.\")\n",
    "\n",
    "    plot_loss_accuracy(train_losses, valid_losses, train_accuracies, valid_accuracies, save_dir)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a489fd",
   "metadata": {},
   "source": [
    "# resnext50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afe8e9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 00:15:22,101 - INFO - Class weights: tensor([1., 1., 1.], device='cuda:0')\n",
      "2025-05-30 00:15:22,101 - INFO - Loading model: resnext50 with 3 classes on cuda\n",
      "2025-05-30 00:15:22,615 - INFO - Model resnext50 loaded with 2048 input features to classifier\n",
      "2025-05-30 00:15:22,740 - INFO - Using mixed precision training: True\n",
      "2025-05-30 00:15:22,742 - INFO - Epoch 1/25\n",
      "2025-05-30 00:15:22,742 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:26,283 - INFO - Training Loss: 1.7972, Accuracy: 0.3438\n",
      "2025-05-30 00:15:26,484 - INFO - Validation Loss: 1.1114, Accuracy: 0.2162\n",
      "2025-05-30 00:15:26,742 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_1.pth\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2025-05-30 00:15:27,178 - INFO - \n",
      "Val Classification Report - Epoch 1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.2162    1.0000    0.3556         8\n",
      "         Sick     0.0000    0.0000    0.0000        14\n",
      "Unknown_class     0.0000    0.0000    0.0000        15\n",
      "\n",
      "     accuracy                         0.2162        37\n",
      "    macro avg     0.0721    0.3333    0.1185        37\n",
      " weighted avg     0.0467    0.2162    0.0769        37\n",
      "\n",
      "2025-05-30 00:15:27,183 - INFO - Val ROC AUC: 0.7428\n",
      "2025-05-30 00:15:27,238 - INFO - Epoch 2/25\n",
      "2025-05-30 00:15:27,239 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:29,180 - INFO - Training Loss: 1.4438, Accuracy: 0.3333\n",
      "2025-05-30 00:15:29,324 - INFO - Validation Loss: 1.1019, Accuracy: 0.2162\n",
      "2025-05-30 00:15:29,733 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_2.pth\n",
      "2025-05-30 00:15:29,780 - INFO - Epoch 3/25\n",
      "2025-05-30 00:15:29,780 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:31,785 - INFO - Training Loss: 1.3155, Accuracy: 0.3125\n",
      "2025-05-30 00:15:31,924 - INFO - Validation Loss: 1.0910, Accuracy: 0.2162\n",
      "2025-05-30 00:15:32,273 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_3.pth\n",
      "2025-05-30 00:15:32,321 - INFO - Epoch 4/25\n",
      "2025-05-30 00:15:32,321 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:34,265 - INFO - Training Loss: 1.2585, Accuracy: 0.3333\n",
      "2025-05-30 00:15:34,401 - INFO - Validation Loss: 1.0798, Accuracy: 0.2162\n",
      "2025-05-30 00:15:34,698 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_4.pth\n",
      "2025-05-30 00:15:34,742 - INFO - Epoch 5/25\n",
      "2025-05-30 00:15:34,742 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:36,590 - INFO - Training Loss: 1.2157, Accuracy: 0.3490\n",
      "2025-05-30 00:15:36,722 - INFO - Validation Loss: 1.0672, Accuracy: 0.2162\n",
      "2025-05-30 00:15:36,918 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_5.pth\n",
      "2025-05-30 00:15:36,968 - INFO - Epoch 6/25\n",
      "2025-05-30 00:15:36,969 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:38,789 - INFO - Training Loss: 1.1919, Accuracy: 0.3490\n",
      "2025-05-30 00:15:38,933 - INFO - Validation Loss: 1.0525, Accuracy: 0.2162\n",
      "2025-05-30 00:15:39,144 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_6.pth\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2025-05-30 00:15:39,481 - INFO - \n",
      "Val Classification Report - Epoch 6:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.2162    1.0000    0.3556         8\n",
      "         Sick     0.0000    0.0000    0.0000        14\n",
      "Unknown_class     0.0000    0.0000    0.0000        15\n",
      "\n",
      "     accuracy                         0.2162        37\n",
      "    macro avg     0.0721    0.3333    0.1185        37\n",
      " weighted avg     0.0467    0.2162    0.0769        37\n",
      "\n",
      "2025-05-30 00:15:39,498 - INFO - Val ROC AUC: 0.9780\n",
      "2025-05-30 00:15:39,544 - INFO - Epoch 7/25\n",
      "2025-05-30 00:15:39,544 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:41,431 - INFO - Training Loss: 1.1375, Accuracy: 0.3854\n",
      "2025-05-30 00:15:41,568 - INFO - Validation Loss: 1.0338, Accuracy: 0.2162\n",
      "2025-05-30 00:15:41,762 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_7.pth\n",
      "2025-05-30 00:15:41,804 - INFO - Epoch 8/25\n",
      "2025-05-30 00:15:41,804 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:43,662 - INFO - Training Loss: 1.1115, Accuracy: 0.4375\n",
      "2025-05-30 00:15:43,787 - INFO - Validation Loss: 1.0123, Accuracy: 0.2432\n",
      "2025-05-30 00:15:43,969 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_8.pth\n",
      "2025-05-30 00:15:44,011 - INFO - Epoch 9/25\n",
      "2025-05-30 00:15:44,017 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:45,922 - INFO - Training Loss: 1.0793, Accuracy: 0.4375\n",
      "2025-05-30 00:15:46,062 - INFO - Validation Loss: 0.9902, Accuracy: 0.3514\n",
      "2025-05-30 00:15:46,252 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_9.pth\n",
      "2025-05-30 00:15:46,293 - INFO - Epoch 10/25\n",
      "2025-05-30 00:15:46,293 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:48,149 - INFO - Training Loss: 1.0427, Accuracy: 0.5000\n",
      "2025-05-30 00:15:48,288 - INFO - Validation Loss: 0.9641, Accuracy: 0.4865\n",
      "2025-05-30 00:15:48,482 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_10.pth\n",
      "2025-05-30 00:15:48,529 - INFO - Epoch 11/25\n",
      "2025-05-30 00:15:48,530 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:50,410 - INFO - Training Loss: 1.0308, Accuracy: 0.5156\n",
      "2025-05-30 00:15:50,544 - INFO - Validation Loss: 0.9375, Accuracy: 0.7027\n",
      "2025-05-30 00:15:50,747 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_11.pth\n",
      "2025-05-30 00:15:51,102 - INFO - \n",
      "Val Classification Report - Epoch 11:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.4211    1.0000    0.5926         8\n",
      "         Sick     1.0000    0.5000    0.6667        14\n",
      "Unknown_class     1.0000    0.7333    0.8462        15\n",
      "\n",
      "     accuracy                         0.7027        37\n",
      "    macro avg     0.8070    0.7444    0.7018        37\n",
      " weighted avg     0.8748    0.7027    0.7234        37\n",
      "\n",
      "2025-05-30 00:15:51,102 - INFO - Val ROC AUC: 0.9670\n",
      "2025-05-30 00:15:51,183 - INFO - Epoch 12/25\n",
      "2025-05-30 00:15:51,183 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:53,058 - INFO - Training Loss: 0.9947, Accuracy: 0.6354\n",
      "2025-05-30 00:15:53,194 - INFO - Validation Loss: 0.9102, Accuracy: 0.7838\n",
      "2025-05-30 00:15:53,398 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_12.pth\n",
      "2025-05-30 00:15:53,442 - INFO - Epoch 13/25\n",
      "2025-05-30 00:15:53,444 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:55,308 - INFO - Training Loss: 0.9463, Accuracy: 0.7031\n",
      "2025-05-30 00:15:55,434 - INFO - Validation Loss: 0.8811, Accuracy: 0.8649\n",
      "2025-05-30 00:15:55,630 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_13.pth\n",
      "2025-05-30 00:15:55,671 - INFO - Epoch 14/25\n",
      "2025-05-30 00:15:55,671 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:57,523 - INFO - Training Loss: 0.9395, Accuracy: 0.7135\n",
      "2025-05-30 00:15:57,661 - INFO - Validation Loss: 0.8497, Accuracy: 0.8919\n",
      "2025-05-30 00:15:57,835 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_14.pth\n",
      "2025-05-30 00:15:57,877 - INFO - Epoch 15/25\n",
      "2025-05-30 00:15:57,877 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:15:59,730 - INFO - Training Loss: 0.9142, Accuracy: 0.6875\n",
      "2025-05-30 00:15:59,857 - INFO - Validation Loss: 0.8177, Accuracy: 0.8919\n",
      "2025-05-30 00:16:00,041 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_15.pth\n",
      "2025-05-30 00:16:00,074 - INFO - Epoch 16/25\n",
      "2025-05-30 00:16:00,074 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:16:01,942 - INFO - Training Loss: 0.8745, Accuracy: 0.7656\n",
      "2025-05-30 00:16:02,071 - INFO - Validation Loss: 0.7867, Accuracy: 0.9189\n",
      "2025-05-30 00:16:02,279 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_16.pth\n",
      "2025-05-30 00:16:02,628 - INFO - \n",
      "Val Classification Report - Epoch 16:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.7273    1.0000    0.8421         8\n",
      "         Sick     1.0000    0.7857    0.8800        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9189        37\n",
      "    macro avg     0.9091    0.9286    0.9074        37\n",
      " weighted avg     0.9410    0.9189    0.9205        37\n",
      "\n",
      "2025-05-30 00:16:02,628 - WARNING - ROC AUC computation failed for val: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "2025-05-30 00:16:02,676 - INFO - Epoch 17/25\n",
      "2025-05-30 00:16:02,683 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:16:04,534 - INFO - Training Loss: 0.8470, Accuracy: 0.7760\n",
      "2025-05-30 00:16:04,672 - INFO - Validation Loss: 0.7561, Accuracy: 0.9189\n",
      "2025-05-30 00:16:04,861 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_17.pth\n",
      "2025-05-30 00:16:04,909 - INFO - Epoch 18/25\n",
      "2025-05-30 00:16:04,909 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:16:06,774 - INFO - Training Loss: 0.7951, Accuracy: 0.8073\n",
      "2025-05-30 00:16:06,913 - INFO - Validation Loss: 0.7241, Accuracy: 0.9189\n",
      "2025-05-30 00:16:07,129 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_18.pth\n",
      "2025-05-30 00:16:07,178 - INFO - Epoch 19/25\n",
      "2025-05-30 00:16:07,178 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:16:09,063 - INFO - Training Loss: 0.7520, Accuracy: 0.8281\n",
      "2025-05-30 00:16:09,196 - INFO - Validation Loss: 0.6873, Accuracy: 0.9189\n",
      "2025-05-30 00:16:09,388 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_19.pth\n",
      "2025-05-30 00:16:09,432 - INFO - Epoch 20/25\n",
      "2025-05-30 00:16:09,432 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:16:11,261 - INFO - Training Loss: 0.7168, Accuracy: 0.8490\n",
      "2025-05-30 00:16:11,393 - INFO - Validation Loss: 0.6437, Accuracy: 0.9189\n",
      "2025-05-30 00:16:11,581 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_20.pth\n",
      "2025-05-30 00:16:11,623 - INFO - Epoch 21/25\n",
      "2025-05-30 00:16:11,630 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:16:13,510 - INFO - Training Loss: 0.6408, Accuracy: 0.8958\n",
      "2025-05-30 00:16:13,643 - INFO - Validation Loss: 0.6022, Accuracy: 0.9459\n",
      "2025-05-30 00:16:13,825 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_21.pth\n",
      "2025-05-30 00:16:14,194 - INFO - \n",
      "Val Classification Report - Epoch 21:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.8000    1.0000    0.8889         8\n",
      "         Sick     1.0000    0.8571    0.9231        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9459        37\n",
      "    macro avg     0.9333    0.9524    0.9373        37\n",
      " weighted avg     0.9568    0.9459    0.9469        37\n",
      "\n",
      "2025-05-30 00:16:14,194 - INFO - Val ROC AUC: 0.9862\n",
      "2025-05-30 00:16:14,246 - INFO - Epoch 22/25\n",
      "2025-05-30 00:16:14,246 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:16:16,100 - INFO - Training Loss: 0.6461, Accuracy: 0.8542\n",
      "2025-05-30 00:16:16,238 - INFO - Validation Loss: 0.5529, Accuracy: 0.9459\n",
      "2025-05-30 00:16:16,436 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_22.pth\n",
      "2025-05-30 00:16:16,479 - INFO - Epoch 23/25\n",
      "2025-05-30 00:16:16,479 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:16:18,330 - INFO - Training Loss: 0.6019, Accuracy: 0.8854\n",
      "2025-05-30 00:16:18,471 - INFO - Validation Loss: 0.5035, Accuracy: 0.9459\n",
      "2025-05-30 00:16:18,949 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_23.pth\n",
      "2025-05-30 00:16:19,002 - INFO - Epoch 24/25\n",
      "2025-05-30 00:16:19,002 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:16:20,841 - INFO - Training Loss: 0.5664, Accuracy: 0.8750\n",
      "2025-05-30 00:16:20,973 - INFO - Validation Loss: 0.4548, Accuracy: 0.9459\n",
      "2025-05-30 00:16:21,156 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_24.pth\n",
      "2025-05-30 00:16:21,206 - INFO - Epoch 25/25\n",
      "2025-05-30 00:16:21,206 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:16:23,283 - INFO - Training Loss: 0.5250, Accuracy: 0.9010\n",
      "2025-05-30 00:16:23,422 - INFO - Validation Loss: 0.4033, Accuracy: 0.9459\n",
      "2025-05-30 00:16:23,611 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext50_epoch_25.pth\n",
      "2025-05-30 00:16:23,659 - INFO - Loading best model weights from epoch 25\n",
      "2025-05-30 00:16:24,960 - INFO - \n",
      "Test Classification Report - Epoch 25:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.5714    1.0000    0.7273         8\n",
      "         Sick     1.0000    0.6250    0.7692        16\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.8462        39\n",
      "    macro avg     0.8571    0.8750    0.8322        39\n",
      " weighted avg     0.9121    0.8462    0.8494        39\n",
      "\n",
      "2025-05-30 00:16:24,960 - WARNING - ROC AUC computation failed for test: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weights = compute_class_weights(train_df_balanced)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"resnext50\"\n",
    "model = get_model(model_name, num_classes, device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True, save_dir=save_dir)\n",
    "\n",
    "trained_model = train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    model_name_prefix=model_name,\n",
    "    class_weights=class_weights,\n",
    "    epochs=25,\n",
    "    device=device,\n",
    "    early_stopping=early_stopping,\n",
    "    save_dir=save_dir,\n",
    "    accum_steps=4,\n",
    "    class_names=['normal', 'Sick', 'Unknown_class']\n",
    ")\n",
    "\n",
    "compute_metrics(trained_model, test_loader, device, epoch=early_stopping.best_epoch + 1 or 25, \n",
    "                split_name=\"test\", save_dir=save_dir, class_names=['normal', 'Sick', 'Unknown_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf1781a",
   "metadata": {},
   "source": [
    "# Resnet18 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78a65277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 00:17:15,116 - INFO - Class weights: tensor([1., 1., 1.], device='cuda:0')\n",
      "2025-05-30 00:17:15,117 - INFO - Loading model: resnet18 with 3 classes on cuda\n",
      "2025-05-30 00:17:15,531 - INFO - Model resnet18 loaded with 512 input features to classifier\n",
      "2025-05-30 00:17:15,574 - INFO - Using mixed precision training: True\n",
      "2025-05-30 00:17:15,574 - INFO - Epoch 1/25\n",
      "2025-05-30 00:17:15,582 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:17,002 - INFO - Training Loss: 1.4099, Accuracy: 0.3958\n",
      "2025-05-30 00:17:17,140 - INFO - Validation Loss: 1.0496, Accuracy: 0.3784\n",
      "2025-05-30 00:17:17,216 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_1.pth\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2025-05-30 00:17:17,512 - INFO - \n",
      "Val Classification Report - Epoch 1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.0000    0.0000    0.0000         8\n",
      "         Sick     0.4000    1.0000    0.5714        14\n",
      "Unknown_class     0.0000    0.0000    0.0000        15\n",
      "\n",
      "     accuracy                         0.3784        37\n",
      "    macro avg     0.1333    0.3333    0.1905        37\n",
      " weighted avg     0.1514    0.3784    0.2162        37\n",
      "\n",
      "2025-05-30 00:17:17,512 - INFO - Val ROC AUC: 0.7507\n",
      "2025-05-30 00:17:17,529 - INFO - Epoch 2/25\n",
      "2025-05-30 00:17:17,529 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:18,462 - INFO - Training Loss: 1.2380, Accuracy: 0.4167\n",
      "2025-05-30 00:17:18,545 - INFO - Validation Loss: 1.0104, Accuracy: 0.4865\n",
      "2025-05-30 00:17:18,647 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_2.pth\n",
      "2025-05-30 00:17:18,661 - INFO - Epoch 3/25\n",
      "2025-05-30 00:17:18,662 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:19,676 - INFO - Training Loss: 1.1251, Accuracy: 0.5729\n",
      "2025-05-30 00:17:19,758 - INFO - Validation Loss: 0.9607, Accuracy: 0.8108\n",
      "2025-05-30 00:17:19,826 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_3.pth\n",
      "2025-05-30 00:17:19,840 - INFO - Epoch 4/25\n",
      "2025-05-30 00:17:19,840 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:20,842 - INFO - Training Loss: 1.0617, Accuracy: 0.6250\n",
      "2025-05-30 00:17:20,918 - INFO - Validation Loss: 0.9081, Accuracy: 0.8108\n",
      "2025-05-30 00:17:20,998 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_4.pth\n",
      "2025-05-30 00:17:21,014 - INFO - Epoch 5/25\n",
      "2025-05-30 00:17:21,014 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:21,980 - INFO - Training Loss: 0.9804, Accuracy: 0.7188\n",
      "2025-05-30 00:17:22,076 - INFO - Validation Loss: 0.8476, Accuracy: 0.8919\n",
      "2025-05-30 00:17:22,160 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_5.pth\n",
      "2025-05-30 00:17:22,185 - INFO - Epoch 6/25\n",
      "2025-05-30 00:17:22,186 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:23,127 - INFO - Training Loss: 0.9563, Accuracy: 0.6875\n",
      "2025-05-30 00:17:23,207 - INFO - Validation Loss: 0.7816, Accuracy: 0.9189\n",
      "2025-05-30 00:17:23,331 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_6.pth\n",
      "2025-05-30 00:17:23,639 - INFO - \n",
      "Val Classification Report - Epoch 6:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.7273    1.0000    0.8421         8\n",
      "         Sick     1.0000    0.7857    0.8800        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9189        37\n",
      "    macro avg     0.9091    0.9286    0.9074        37\n",
      " weighted avg     0.9410    0.9189    0.9205        37\n",
      "\n",
      "2025-05-30 00:17:23,645 - INFO - Val ROC AUC: 0.9831\n",
      "2025-05-30 00:17:23,655 - INFO - Epoch 7/25\n",
      "2025-05-30 00:17:23,655 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:24,572 - INFO - Training Loss: 0.8722, Accuracy: 0.7708\n",
      "2025-05-30 00:17:24,669 - INFO - Validation Loss: 0.7100, Accuracy: 0.9189\n",
      "2025-05-30 00:17:24,747 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_7.pth\n",
      "2025-05-30 00:17:24,766 - INFO - Epoch 8/25\n",
      "2025-05-30 00:17:24,767 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:25,698 - INFO - Training Loss: 0.8231, Accuracy: 0.8281\n",
      "2025-05-30 00:17:25,775 - INFO - Validation Loss: 0.6405, Accuracy: 0.9189\n",
      "2025-05-30 00:17:25,858 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_8.pth\n",
      "2025-05-30 00:17:25,872 - INFO - Epoch 9/25\n",
      "2025-05-30 00:17:25,874 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:26,853 - INFO - Training Loss: 0.7765, Accuracy: 0.8125\n",
      "2025-05-30 00:17:26,942 - INFO - Validation Loss: 0.5720, Accuracy: 0.9189\n",
      "2025-05-30 00:17:27,034 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_9.pth\n",
      "2025-05-30 00:17:27,050 - INFO - Epoch 10/25\n",
      "2025-05-30 00:17:27,051 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:28,008 - INFO - Training Loss: 0.7090, Accuracy: 0.8333\n",
      "2025-05-30 00:17:28,091 - INFO - Validation Loss: 0.5069, Accuracy: 0.9189\n",
      "2025-05-30 00:17:28,196 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_10.pth\n",
      "2025-05-30 00:17:28,210 - INFO - Epoch 11/25\n",
      "2025-05-30 00:17:28,216 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:29,156 - INFO - Training Loss: 0.6593, Accuracy: 0.8646\n",
      "2025-05-30 00:17:29,247 - INFO - Validation Loss: 0.4444, Accuracy: 0.9459\n",
      "2025-05-30 00:17:29,323 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_11.pth\n",
      "2025-05-30 00:17:29,609 - INFO - \n",
      "Val Classification Report - Epoch 11:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.8000    1.0000    0.8889         8\n",
      "         Sick     1.0000    0.8571    0.9231        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9459        37\n",
      "    macro avg     0.9333    0.9524    0.9373        37\n",
      " weighted avg     0.9568    0.9459    0.9469        37\n",
      "\n",
      "2025-05-30 00:17:29,615 - INFO - Val ROC AUC: 0.9852\n",
      "2025-05-30 00:17:29,629 - INFO - Epoch 12/25\n",
      "2025-05-30 00:17:29,629 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:30,602 - INFO - Training Loss: 0.6012, Accuracy: 0.8750\n",
      "2025-05-30 00:17:30,687 - INFO - Validation Loss: 0.3890, Accuracy: 0.9459\n",
      "2025-05-30 00:17:30,771 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_12.pth\n",
      "2025-05-30 00:17:30,788 - INFO - Epoch 13/25\n",
      "2025-05-30 00:17:30,790 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:31,764 - INFO - Training Loss: 0.5573, Accuracy: 0.8646\n",
      "2025-05-30 00:17:31,849 - INFO - Validation Loss: 0.3417, Accuracy: 0.9459\n",
      "2025-05-30 00:17:31,932 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_13.pth\n",
      "2025-05-30 00:17:31,945 - INFO - Epoch 14/25\n",
      "2025-05-30 00:17:31,945 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:32,887 - INFO - Training Loss: 0.5123, Accuracy: 0.9010\n",
      "2025-05-30 00:17:32,975 - INFO - Validation Loss: 0.3017, Accuracy: 0.9459\n",
      "2025-05-30 00:17:33,080 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_14.pth\n",
      "2025-05-30 00:17:33,100 - INFO - Epoch 15/25\n",
      "2025-05-30 00:17:33,100 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:34,043 - INFO - Training Loss: 0.4657, Accuracy: 0.9010\n",
      "2025-05-30 00:17:34,130 - INFO - Validation Loss: 0.2704, Accuracy: 0.9189\n",
      "2025-05-30 00:17:34,222 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_15.pth\n",
      "2025-05-30 00:17:34,239 - INFO - Epoch 16/25\n",
      "2025-05-30 00:17:34,241 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:35,174 - INFO - Training Loss: 0.4570, Accuracy: 0.8958\n",
      "2025-05-30 00:17:35,264 - INFO - Validation Loss: 0.2442, Accuracy: 0.9189\n",
      "2025-05-30 00:17:35,356 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_16.pth\n",
      "2025-05-30 00:17:35,668 - INFO - \n",
      "Val Classification Report - Epoch 16:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.7778    0.8750    0.8235         8\n",
      "         Sick     0.9231    0.8571    0.8889        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9189        37\n",
      "    macro avg     0.9003    0.9107    0.9041        37\n",
      " weighted avg     0.9228    0.9189    0.9198        37\n",
      "\n",
      "2025-05-30 00:17:35,668 - INFO - Val ROC AUC: 0.9856\n",
      "2025-05-30 00:17:35,690 - INFO - Epoch 17/25\n",
      "2025-05-30 00:17:35,692 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:36,655 - INFO - Training Loss: 0.4095, Accuracy: 0.8958\n",
      "2025-05-30 00:17:36,747 - INFO - Validation Loss: 0.2259, Accuracy: 0.9189\n",
      "2025-05-30 00:17:36,857 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_17.pth\n",
      "2025-05-30 00:17:36,878 - INFO - Epoch 18/25\n",
      "2025-05-30 00:17:36,879 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:37,894 - INFO - Training Loss: 0.4110, Accuracy: 0.9010\n",
      "2025-05-30 00:17:37,983 - INFO - Validation Loss: 0.2146, Accuracy: 0.9459\n",
      "2025-05-30 00:17:38,068 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_18.pth\n",
      "2025-05-30 00:17:38,085 - INFO - Epoch 19/25\n",
      "2025-05-30 00:17:38,085 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:39,049 - INFO - Training Loss: 0.3774, Accuracy: 0.8906\n",
      "2025-05-30 00:17:39,133 - INFO - Validation Loss: 0.2061, Accuracy: 0.9459\n",
      "2025-05-30 00:17:39,216 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_19.pth\n",
      "2025-05-30 00:17:39,236 - INFO - Epoch 20/25\n",
      "2025-05-30 00:17:39,237 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:40,176 - INFO - Training Loss: 0.3190, Accuracy: 0.9271\n",
      "2025-05-30 00:17:40,262 - INFO - Validation Loss: 0.2004, Accuracy: 0.9459\n",
      "2025-05-30 00:17:40,353 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_20.pth\n",
      "2025-05-30 00:17:40,371 - INFO - Epoch 21/25\n",
      "2025-05-30 00:17:40,371 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:41,339 - INFO - Training Loss: 0.2763, Accuracy: 0.9583\n",
      "2025-05-30 00:17:41,428 - INFO - Validation Loss: 0.1930, Accuracy: 0.9459\n",
      "2025-05-30 00:17:41,535 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_21.pth\n",
      "2025-05-30 00:17:41,867 - INFO - \n",
      "Val Classification Report - Epoch 21:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.8750    0.8750    0.8750         8\n",
      "         Sick     0.9286    0.9286    0.9286        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9459        37\n",
      "    macro avg     0.9345    0.9345    0.9345        37\n",
      " weighted avg     0.9459    0.9459    0.9459        37\n",
      "\n",
      "2025-05-30 00:17:41,867 - INFO - Val ROC AUC: 0.9852\n",
      "2025-05-30 00:17:41,881 - INFO - Epoch 22/25\n",
      "2025-05-30 00:17:41,881 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:42,823 - INFO - Training Loss: 0.2424, Accuracy: 0.9479\n",
      "2025-05-30 00:17:42,904 - INFO - Validation Loss: 0.1860, Accuracy: 0.9459\n",
      "2025-05-30 00:17:42,981 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_22.pth\n",
      "2025-05-30 00:17:42,994 - INFO - Epoch 23/25\n",
      "2025-05-30 00:17:42,994 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:43,940 - INFO - Training Loss: 0.2260, Accuracy: 0.9740\n",
      "2025-05-30 00:17:44,038 - INFO - Validation Loss: 0.1788, Accuracy: 0.9459\n",
      "2025-05-30 00:17:44,108 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_23.pth\n",
      "2025-05-30 00:17:44,121 - INFO - Epoch 24/25\n",
      "2025-05-30 00:17:44,121 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:45,077 - INFO - Training Loss: 0.2061, Accuracy: 0.9688\n",
      "2025-05-30 00:17:45,172 - INFO - Validation Loss: 0.1724, Accuracy: 0.9459\n",
      "2025-05-30 00:17:45,249 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_24.pth\n",
      "2025-05-30 00:17:45,261 - INFO - Epoch 25/25\n",
      "2025-05-30 00:17:45,261 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:17:46,271 - INFO - Training Loss: 0.2223, Accuracy: 0.9375\n",
      "2025-05-30 00:17:46,357 - INFO - Validation Loss: 0.1703, Accuracy: 0.9459\n",
      "2025-05-30 00:17:46,458 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet18_epoch_25.pth\n",
      "2025-05-30 00:17:46,472 - INFO - Loading best model weights from epoch 25\n",
      "2025-05-30 00:17:47,286 - INFO - \n",
      "Test Classification Report - Epoch 25:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.5455    0.7500    0.6316         8\n",
      "         Sick     0.8462    0.6875    0.7586        16\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.8205        39\n",
      "    macro avg     0.7972    0.8125    0.7967        39\n",
      " weighted avg     0.8436    0.8205    0.8254        39\n",
      "\n",
      "2025-05-30 00:17:47,286 - WARNING - ROC AUC computation failed for test: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weights = compute_class_weights(train_df_balanced)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"resnet18\"\n",
    "model = get_model(model_name, num_classes, device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True, save_dir=save_dir)\n",
    "\n",
    "trained_model = train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    model_name_prefix=model_name,\n",
    "    class_weights=class_weights,\n",
    "    epochs=25,\n",
    "    device=device,\n",
    "    early_stopping=early_stopping,\n",
    "    save_dir=save_dir,\n",
    "    accum_steps=4,\n",
    "    class_names=['normal', 'Sick', 'Unknown_class']\n",
    ")\n",
    "\n",
    "compute_metrics(trained_model, test_loader, device, epoch=early_stopping.best_epoch + 1 or 25, \n",
    "                split_name=\"test\", save_dir=save_dir, class_names=['normal', 'Sick', 'Unknown_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b44c6",
   "metadata": {},
   "source": [
    "# resnext101 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52185367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 00:18:39,536 - INFO - Class weights: tensor([1., 1., 1.], device='cuda:0')\n",
      "2025-05-30 00:18:39,536 - INFO - Loading model: resnext101 with 3 classes on cuda\n",
      "2025-05-30 00:18:41,632 - INFO - Model resnext101 loaded with 2048 input features to classifier\n",
      "2025-05-30 00:18:41,978 - INFO - Using mixed precision training: True\n",
      "2025-05-30 00:18:41,979 - INFO - Epoch 1/25\n",
      "2025-05-30 00:18:41,979 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:19:11,116 - INFO - Training Loss: 1.6300, Accuracy: 0.2917\n",
      "2025-05-30 00:19:12,799 - INFO - Validation Loss: 1.0905, Accuracy: 0.3784\n",
      "2025-05-30 00:19:13,467 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_1.pth\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2025-05-30 00:19:15,353 - INFO - \n",
      "Val Classification Report - Epoch 1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.0000    0.0000    0.0000         8\n",
      "         Sick     0.3784    1.0000    0.5490        14\n",
      "Unknown_class     0.0000    0.0000    0.0000        15\n",
      "\n",
      "     accuracy                         0.3784        37\n",
      "    macro avg     0.1261    0.3333    0.1830        37\n",
      " weighted avg     0.1432    0.3784    0.2077        37\n",
      "\n",
      "2025-05-30 00:19:15,361 - INFO - Val ROC AUC: 0.7286\n",
      "2025-05-30 00:19:15,923 - INFO - Epoch 2/25\n",
      "2025-05-30 00:19:15,923 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:19:43,797 - INFO - Training Loss: 1.3968, Accuracy: 0.3646\n",
      "2025-05-30 00:19:45,756 - INFO - Validation Loss: 1.0861, Accuracy: 0.3784\n",
      "2025-05-30 00:19:46,435 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_2.pth\n",
      "2025-05-30 00:19:46,982 - INFO - Epoch 3/25\n",
      "2025-05-30 00:19:46,982 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:20:13,754 - INFO - Training Loss: 1.3121, Accuracy: 0.3646\n",
      "2025-05-30 00:20:15,500 - INFO - Validation Loss: 1.0816, Accuracy: 0.4054\n",
      "2025-05-30 00:20:16,207 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_3.pth\n",
      "2025-05-30 00:20:16,717 - INFO - Epoch 4/25\n",
      "2025-05-30 00:20:16,717 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:20:44,472 - INFO - Training Loss: 1.2788, Accuracy: 0.4271\n",
      "2025-05-30 00:20:46,272 - INFO - Validation Loss: 1.0750, Accuracy: 0.4865\n",
      "2025-05-30 00:20:46,911 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_4.pth\n",
      "2025-05-30 00:20:47,441 - INFO - Epoch 5/25\n",
      "2025-05-30 00:20:47,441 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:21:15,092 - INFO - Training Loss: 1.2403, Accuracy: 0.4948\n",
      "2025-05-30 00:21:16,931 - INFO - Validation Loss: 1.0674, Accuracy: 0.5676\n",
      "2025-05-30 00:21:17,524 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_5.pth\n",
      "2025-05-30 00:21:18,066 - INFO - Epoch 6/25\n",
      "2025-05-30 00:21:18,068 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:21:44,409 - INFO - Training Loss: 1.2139, Accuracy: 0.6042\n",
      "2025-05-30 00:21:46,069 - INFO - Validation Loss: 1.0565, Accuracy: 0.7297\n",
      "2025-05-30 00:21:46,763 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_6.pth\n",
      "2025-05-30 00:21:48,963 - INFO - \n",
      "Val Classification Report - Epoch 6:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     1.0000    0.1250    0.2222         8\n",
      "         Sick     0.5833    1.0000    0.7368        14\n",
      "Unknown_class     1.0000    0.8000    0.8889        15\n",
      "\n",
      "     accuracy                         0.7297        37\n",
      "    macro avg     0.8611    0.6417    0.6160        37\n",
      " weighted avg     0.8423    0.7297    0.6872        37\n",
      "\n",
      "2025-05-30 00:21:48,968 - INFO - Val ROC AUC: 0.9500\n",
      "2025-05-30 00:21:49,496 - INFO - Epoch 7/25\n",
      "2025-05-30 00:21:49,497 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:22:15,975 - INFO - Training Loss: 1.1803, Accuracy: 0.6406\n",
      "2025-05-30 00:22:17,635 - INFO - Validation Loss: 1.0445, Accuracy: 0.7838\n",
      "2025-05-30 00:22:18,886 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_7.pth\n",
      "2025-05-30 00:22:19,431 - INFO - Epoch 8/25\n",
      "2025-05-30 00:22:19,431 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:22:46,320 - INFO - Training Loss: 1.1552, Accuracy: 0.6510\n",
      "2025-05-30 00:22:48,089 - INFO - Validation Loss: 1.0318, Accuracy: 0.7838\n",
      "2025-05-30 00:22:49,166 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_8.pth\n",
      "2025-05-30 00:22:49,804 - INFO - Epoch 9/25\n",
      "2025-05-30 00:22:49,805 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:23:17,438 - INFO - Training Loss: 1.1154, Accuracy: 0.7135\n",
      "2025-05-30 00:23:19,694 - INFO - Validation Loss: 1.0171, Accuracy: 0.8649\n",
      "2025-05-30 00:23:20,564 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_9.pth\n",
      "2025-05-30 00:23:21,129 - INFO - Epoch 10/25\n",
      "2025-05-30 00:23:21,129 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:23:47,817 - INFO - Training Loss: 1.0954, Accuracy: 0.7292\n",
      "2025-05-30 00:23:50,057 - INFO - Validation Loss: 0.9999, Accuracy: 0.9189\n",
      "2025-05-30 00:23:50,691 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_10.pth\n",
      "2025-05-30 00:23:51,281 - INFO - Epoch 11/25\n",
      "2025-05-30 00:23:51,289 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:24:17,296 - INFO - Training Loss: 1.0623, Accuracy: 0.8125\n",
      "2025-05-30 00:24:19,013 - INFO - Validation Loss: 0.9806, Accuracy: 0.9459\n",
      "2025-05-30 00:24:19,660 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_11.pth\n",
      "2025-05-30 00:24:21,935 - INFO - \n",
      "Val Classification Report - Epoch 11:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.8000    1.0000    0.8889         8\n",
      "         Sick     1.0000    0.8571    0.9231        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9459        37\n",
      "    macro avg     0.9333    0.9524    0.9373        37\n",
      " weighted avg     0.9568    0.9459    0.9469        37\n",
      "\n",
      "2025-05-30 00:24:21,942 - INFO - Val ROC AUC: 0.9714\n",
      "2025-05-30 00:24:22,500 - INFO - Epoch 12/25\n",
      "2025-05-30 00:24:22,505 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:24:48,429 - INFO - Training Loss: 1.0327, Accuracy: 0.8229\n",
      "2025-05-30 00:24:50,495 - INFO - Validation Loss: 0.9598, Accuracy: 0.9189\n",
      "2025-05-30 00:24:51,602 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_12.pth\n",
      "2025-05-30 00:24:52,187 - INFO - Epoch 13/25\n",
      "2025-05-30 00:24:52,187 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:25:19,076 - INFO - Training Loss: 1.0136, Accuracy: 0.7708\n",
      "2025-05-30 00:25:20,990 - INFO - Validation Loss: 0.9348, Accuracy: 0.9189\n",
      "2025-05-30 00:25:21,698 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_13.pth\n",
      "2025-05-30 00:25:22,297 - INFO - Epoch 14/25\n",
      "2025-05-30 00:25:22,297 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:25:48,283 - INFO - Training Loss: 0.9757, Accuracy: 0.8125\n",
      "2025-05-30 00:25:49,870 - INFO - Validation Loss: 0.9083, Accuracy: 0.9189\n",
      "2025-05-30 00:25:50,495 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_14.pth\n",
      "2025-05-30 00:25:51,101 - INFO - Epoch 15/25\n",
      "2025-05-30 00:25:51,101 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:26:18,123 - INFO - Training Loss: 0.9335, Accuracy: 0.8646\n",
      "2025-05-30 00:26:19,897 - INFO - Validation Loss: 0.8748, Accuracy: 0.9189\n",
      "2025-05-30 00:26:20,523 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_15.pth\n",
      "2025-05-30 00:26:21,100 - INFO - Epoch 16/25\n",
      "2025-05-30 00:26:21,101 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:26:47,497 - INFO - Training Loss: 0.9079, Accuracy: 0.8229\n",
      "2025-05-30 00:26:49,070 - INFO - Validation Loss: 0.8391, Accuracy: 0.9189\n",
      "2025-05-30 00:26:49,928 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_16.pth\n",
      "2025-05-30 00:26:51,727 - INFO - \n",
      "Val Classification Report - Epoch 16:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.7273    1.0000    0.8421         8\n",
      "         Sick     1.0000    0.7857    0.8800        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9189        37\n",
      "    macro avg     0.9091    0.9286    0.9074        37\n",
      " weighted avg     0.9410    0.9189    0.9205        37\n",
      "\n",
      "2025-05-30 00:26:51,728 - INFO - Val ROC AUC: 0.9778\n",
      "2025-05-30 00:26:52,305 - INFO - Epoch 17/25\n",
      "2025-05-30 00:26:52,305 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:27:18,575 - INFO - Training Loss: 0.8713, Accuracy: 0.8333\n",
      "2025-05-30 00:27:20,148 - INFO - Validation Loss: 0.7997, Accuracy: 0.9189\n",
      "2025-05-30 00:27:20,843 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_17.pth\n",
      "2025-05-30 00:27:21,394 - INFO - Epoch 18/25\n",
      "2025-05-30 00:27:21,394 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:27:47,630 - INFO - Training Loss: 0.8280, Accuracy: 0.8646\n",
      "2025-05-30 00:27:49,188 - INFO - Validation Loss: 0.7527, Accuracy: 0.9189\n",
      "2025-05-30 00:27:49,814 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_18.pth\n",
      "2025-05-30 00:27:50,399 - INFO - Epoch 19/25\n",
      "2025-05-30 00:27:50,400 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:28:16,634 - INFO - Training Loss: 0.7599, Accuracy: 0.8646\n",
      "2025-05-30 00:28:18,199 - INFO - Validation Loss: 0.6994, Accuracy: 0.9189\n",
      "2025-05-30 00:28:18,833 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_19.pth\n",
      "2025-05-30 00:28:19,404 - INFO - Epoch 20/25\n",
      "2025-05-30 00:28:19,404 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:28:45,515 - INFO - Training Loss: 0.7366, Accuracy: 0.8698\n",
      "2025-05-30 00:28:47,053 - INFO - Validation Loss: 0.6389, Accuracy: 0.9189\n",
      "2025-05-30 00:28:47,693 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_20.pth\n",
      "2025-05-30 00:28:48,235 - INFO - Epoch 21/25\n",
      "2025-05-30 00:28:48,241 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:29:13,297 - INFO - Training Loss: 0.6659, Accuracy: 0.8646\n",
      "2025-05-30 00:29:14,689 - INFO - Validation Loss: 0.5791, Accuracy: 0.9189\n",
      "2025-05-30 00:29:15,359 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_21.pth\n",
      "2025-05-30 00:29:16,967 - INFO - \n",
      "Val Classification Report - Epoch 21:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.7273    1.0000    0.8421         8\n",
      "         Sick     1.0000    0.7857    0.8800        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9189        37\n",
      "    macro avg     0.9091    0.9286    0.9074        37\n",
      " weighted avg     0.9410    0.9189    0.9205        37\n",
      "\n",
      "2025-05-30 00:29:16,976 - INFO - Val ROC AUC: 0.9848\n",
      "2025-05-30 00:29:17,424 - INFO - Epoch 22/25\n",
      "2025-05-30 00:29:17,427 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:29:42,784 - INFO - Training Loss: 0.6114, Accuracy: 0.8281\n",
      "2025-05-30 00:29:43,859 - INFO - Validation Loss: 0.5106, Accuracy: 0.9189\n",
      "2025-05-30 00:29:44,681 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_22.pth\n",
      "2025-05-30 00:29:45,216 - INFO - Epoch 23/25\n",
      "2025-05-30 00:29:45,216 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:30:10,837 - INFO - Training Loss: 0.5469, Accuracy: 0.8750\n",
      "2025-05-30 00:30:12,005 - INFO - Validation Loss: 0.4466, Accuracy: 0.9189\n",
      "2025-05-30 00:30:12,773 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_23.pth\n",
      "2025-05-30 00:30:13,239 - INFO - Epoch 24/25\n",
      "2025-05-30 00:30:13,239 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:30:40,145 - INFO - Training Loss: 0.5123, Accuracy: 0.8854\n",
      "2025-05-30 00:30:41,531 - INFO - Validation Loss: 0.3813, Accuracy: 0.9459\n",
      "2025-05-30 00:30:42,864 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_24.pth\n",
      "2025-05-30 00:30:43,411 - INFO - Epoch 25/25\n",
      "2025-05-30 00:30:43,411 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:31:10,416 - INFO - Training Loss: 0.4508, Accuracy: 0.8802\n",
      "2025-05-30 00:31:11,786 - INFO - Validation Loss: 0.3260, Accuracy: 0.9459\n",
      "2025-05-30 00:31:12,915 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnext101_epoch_25.pth\n",
      "2025-05-30 00:31:13,530 - INFO - Loading best model weights from epoch 25\n",
      "2025-05-30 00:31:15,301 - INFO - \n",
      "Test Classification Report - Epoch 25:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.5333    1.0000    0.6957         8\n",
      "         Sick     1.0000    0.5625    0.7200        16\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.8205        39\n",
      "    macro avg     0.8444    0.8542    0.8052        39\n",
      " weighted avg     0.9043    0.8205    0.8227        39\n",
      "\n",
      "2025-05-30 00:31:15,301 - WARNING - ROC AUC computation failed for test: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weights = compute_class_weights(train_df_balanced)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"resnext101\"\n",
    "model = get_model(model_name, num_classes, device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True, save_dir=save_dir)\n",
    "\n",
    "trained_model = train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    model_name_prefix=model_name,\n",
    "    class_weights=class_weights,\n",
    "    epochs=25,\n",
    "    device=device,\n",
    "    early_stopping=early_stopping,\n",
    "    save_dir=save_dir,\n",
    "    accum_steps=4,\n",
    "    class_names=['normal', 'Sick', 'Unknown_class']\n",
    ")\n",
    "\n",
    "compute_metrics(trained_model, test_loader, device, epoch=early_stopping.best_epoch + 1 or 25, \n",
    "                split_name=\"test\", save_dir=save_dir, class_names=['normal', 'Sick', 'Unknown_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587329f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f18833d",
   "metadata": {},
   "source": [
    "# resnet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4d3f0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 00:32:23,976 - INFO - Class weights: tensor([1., 1., 1.], device='cuda:0')\n",
      "2025-05-30 00:32:23,983 - INFO - Loading model: resnet50 with 3 classes on cuda\n",
      "2025-05-30 00:32:24,685 - INFO - Model resnet50 loaded with 2048 input features to classifier\n",
      "2025-05-30 00:32:24,791 - INFO - Using mixed precision training: True\n",
      "2025-05-30 00:32:24,791 - INFO - Epoch 1/25\n",
      "2025-05-30 00:32:24,791 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:27,044 - INFO - Training Loss: 1.5849, Accuracy: 0.3542\n",
      "2025-05-30 00:32:27,192 - INFO - Validation Loss: 1.0835, Accuracy: 0.3784\n",
      "2025-05-30 00:32:27,365 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_1.pth\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2025-05-30 00:32:27,681 - INFO - \n",
      "Val Classification Report - Epoch 1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.0000    0.0000    0.0000         8\n",
      "         Sick     0.3784    1.0000    0.5490        14\n",
      "Unknown_class     0.0000    0.0000    0.0000        15\n",
      "\n",
      "     accuracy                         0.3784        37\n",
      "    macro avg     0.1261    0.3333    0.1830        37\n",
      " weighted avg     0.1432    0.3784    0.2077        37\n",
      "\n",
      "2025-05-30 00:32:27,681 - INFO - Val ROC AUC: 0.9476\n",
      "2025-05-30 00:32:27,753 - INFO - Epoch 2/25\n",
      "2025-05-30 00:32:27,753 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:29,298 - INFO - Training Loss: 1.3570, Accuracy: 0.3594\n",
      "2025-05-30 00:32:29,423 - INFO - Validation Loss: 1.0781, Accuracy: 0.3784\n",
      "2025-05-30 00:32:29,658 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_2.pth\n",
      "2025-05-30 00:32:29,698 - INFO - Epoch 3/25\n",
      "2025-05-30 00:32:29,698 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:31,317 - INFO - Training Loss: 1.2652, Accuracy: 0.3750\n",
      "2025-05-30 00:32:31,426 - INFO - Validation Loss: 1.0728, Accuracy: 0.3784\n",
      "2025-05-30 00:32:31,694 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_3.pth\n",
      "2025-05-30 00:32:31,731 - INFO - Epoch 4/25\n",
      "2025-05-30 00:32:31,732 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:33,346 - INFO - Training Loss: 1.2249, Accuracy: 0.4583\n",
      "2025-05-30 00:32:33,468 - INFO - Validation Loss: 1.0681, Accuracy: 0.4054\n",
      "2025-05-30 00:32:33,780 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_4.pth\n",
      "2025-05-30 00:32:33,824 - INFO - Epoch 5/25\n",
      "2025-05-30 00:32:33,824 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:35,518 - INFO - Training Loss: 1.1838, Accuracy: 0.4896\n",
      "2025-05-30 00:32:35,640 - INFO - Validation Loss: 1.0620, Accuracy: 0.5135\n",
      "2025-05-30 00:32:35,919 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_5.pth\n",
      "2025-05-30 00:32:35,952 - INFO - Epoch 6/25\n",
      "2025-05-30 00:32:35,952 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:37,622 - INFO - Training Loss: 1.1613, Accuracy: 0.5156\n",
      "2025-05-30 00:32:37,754 - INFO - Validation Loss: 1.0551, Accuracy: 0.6757\n",
      "2025-05-30 00:32:38,041 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_6.pth\n",
      "2025-05-30 00:32:38,404 - INFO - \n",
      "Val Classification Report - Epoch 6:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     1.0000    0.1250    0.2222         8\n",
      "         Sick     0.5385    1.0000    0.7000        14\n",
      "Unknown_class     1.0000    0.6667    0.8000        15\n",
      "\n",
      "     accuracy                         0.6757        37\n",
      "    macro avg     0.8462    0.5972    0.5741        37\n",
      " weighted avg     0.8254    0.6757    0.6372        37\n",
      "\n",
      "2025-05-30 00:32:38,412 - INFO - Val ROC AUC: 0.9799\n",
      "2025-05-30 00:32:38,453 - INFO - Epoch 7/25\n",
      "2025-05-30 00:32:38,461 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:40,143 - INFO - Training Loss: 1.1468, Accuracy: 0.5833\n",
      "2025-05-30 00:32:40,305 - INFO - Validation Loss: 1.0467, Accuracy: 0.7838\n",
      "2025-05-30 00:32:40,607 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_7.pth\n",
      "2025-05-30 00:32:40,631 - INFO - Epoch 8/25\n",
      "2025-05-30 00:32:40,631 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:42,288 - INFO - Training Loss: 1.1117, Accuracy: 0.7135\n",
      "2025-05-30 00:32:42,412 - INFO - Validation Loss: 1.0359, Accuracy: 0.8378\n",
      "2025-05-30 00:32:42,730 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_8.pth\n",
      "2025-05-30 00:32:42,763 - INFO - Epoch 9/25\n",
      "2025-05-30 00:32:42,763 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:44,412 - INFO - Training Loss: 1.0917, Accuracy: 0.7135\n",
      "2025-05-30 00:32:44,535 - INFO - Validation Loss: 1.0219, Accuracy: 0.8378\n",
      "2025-05-30 00:32:44,821 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_9.pth\n",
      "2025-05-30 00:32:44,862 - INFO - Epoch 10/25\n",
      "2025-05-30 00:32:44,862 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:46,525 - INFO - Training Loss: 1.0808, Accuracy: 0.6979\n",
      "2025-05-30 00:32:46,648 - INFO - Validation Loss: 1.0062, Accuracy: 0.8919\n",
      "2025-05-30 00:32:46,928 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_10.pth\n",
      "2025-05-30 00:32:46,961 - INFO - Epoch 11/25\n",
      "2025-05-30 00:32:46,961 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:48,585 - INFO - Training Loss: 1.0651, Accuracy: 0.8021\n",
      "2025-05-30 00:32:48,715 - INFO - Validation Loss: 0.9876, Accuracy: 0.8919\n",
      "2025-05-30 00:32:49,061 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_11.pth\n",
      "2025-05-30 00:32:49,426 - INFO - \n",
      "Val Classification Report - Epoch 11:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.7500    0.7500    0.7500         8\n",
      "         Sick     0.8571    0.8571    0.8571        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.8919        37\n",
      "    macro avg     0.8690    0.8690    0.8690        37\n",
      " weighted avg     0.8919    0.8919    0.8919        37\n",
      "\n",
      "2025-05-30 00:32:49,436 - INFO - Val ROC AUC: 0.9778\n",
      "2025-05-30 00:32:49,467 - INFO - Epoch 12/25\n",
      "2025-05-30 00:32:49,475 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:51,108 - INFO - Training Loss: 1.0265, Accuracy: 0.8073\n",
      "2025-05-30 00:32:51,237 - INFO - Validation Loss: 0.9643, Accuracy: 0.9189\n",
      "2025-05-30 00:32:51,506 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_12.pth\n",
      "2025-05-30 00:32:51,539 - INFO - Epoch 13/25\n",
      "2025-05-30 00:32:51,539 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:53,198 - INFO - Training Loss: 1.0066, Accuracy: 0.8385\n",
      "2025-05-30 00:32:53,330 - INFO - Validation Loss: 0.9365, Accuracy: 0.9189\n",
      "2025-05-30 00:32:53,623 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_13.pth\n",
      "2025-05-30 00:32:53,655 - INFO - Epoch 14/25\n",
      "2025-05-30 00:32:53,655 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:55,290 - INFO - Training Loss: 0.9881, Accuracy: 0.8229\n",
      "2025-05-30 00:32:55,409 - INFO - Validation Loss: 0.9039, Accuracy: 0.9459\n",
      "2025-05-30 00:32:55,679 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_14.pth\n",
      "2025-05-30 00:32:55,709 - INFO - Epoch 15/25\n",
      "2025-05-30 00:32:55,724 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:57,375 - INFO - Training Loss: 0.9394, Accuracy: 0.8750\n",
      "2025-05-30 00:32:57,512 - INFO - Validation Loss: 0.8651, Accuracy: 0.9459\n",
      "2025-05-30 00:32:57,766 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_15.pth\n",
      "2025-05-30 00:32:57,810 - INFO - Epoch 16/25\n",
      "2025-05-30 00:32:57,811 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:32:59,569 - INFO - Training Loss: 0.9013, Accuracy: 0.8698\n",
      "2025-05-30 00:32:59,703 - INFO - Validation Loss: 0.8192, Accuracy: 0.9459\n",
      "2025-05-30 00:33:00,003 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_16.pth\n",
      "2025-05-30 00:33:00,378 - INFO - \n",
      "Val Classification Report - Epoch 16:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.8000    1.0000    0.8889         8\n",
      "         Sick     1.0000    0.8571    0.9231        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9459        37\n",
      "    macro avg     0.9333    0.9524    0.9373        37\n",
      " weighted avg     0.9568    0.9459    0.9469        37\n",
      "\n",
      "2025-05-30 00:33:00,378 - INFO - Val ROC AUC: 0.9800\n",
      "2025-05-30 00:33:00,423 - INFO - Epoch 17/25\n",
      "2025-05-30 00:33:00,423 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:33:02,054 - INFO - Training Loss: 0.8612, Accuracy: 0.8490\n",
      "2025-05-30 00:33:02,197 - INFO - Validation Loss: 0.7638, Accuracy: 0.9459\n",
      "2025-05-30 00:33:02,497 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_17.pth\n",
      "2025-05-30 00:33:02,542 - INFO - Epoch 18/25\n",
      "2025-05-30 00:33:02,542 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:33:04,223 - INFO - Training Loss: 0.7871, Accuracy: 0.8542\n",
      "2025-05-30 00:33:04,358 - INFO - Validation Loss: 0.7003, Accuracy: 0.9459\n",
      "2025-05-30 00:33:04,900 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_18.pth\n",
      "2025-05-30 00:33:04,930 - INFO - Epoch 19/25\n",
      "2025-05-30 00:33:04,930 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:33:06,536 - INFO - Training Loss: 0.7349, Accuracy: 0.8594\n",
      "2025-05-30 00:33:06,672 - INFO - Validation Loss: 0.6326, Accuracy: 0.9459\n",
      "2025-05-30 00:33:07,002 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_19.pth\n",
      "2025-05-30 00:33:07,047 - INFO - Epoch 20/25\n",
      "2025-05-30 00:33:07,047 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:33:08,750 - INFO - Training Loss: 0.7071, Accuracy: 0.8750\n",
      "2025-05-30 00:33:08,882 - INFO - Validation Loss: 0.5673, Accuracy: 0.9459\n",
      "2025-05-30 00:33:09,151 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_20.pth\n",
      "2025-05-30 00:33:09,181 - INFO - Epoch 21/25\n",
      "2025-05-30 00:33:09,181 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:33:10,850 - INFO - Training Loss: 0.6334, Accuracy: 0.8490\n",
      "2025-05-30 00:33:10,981 - INFO - Validation Loss: 0.5081, Accuracy: 0.9459\n",
      "2025-05-30 00:33:11,254 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_21.pth\n",
      "2025-05-30 00:33:11,629 - INFO - \n",
      "Val Classification Report - Epoch 21:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.8000    1.0000    0.8889         8\n",
      "         Sick     1.0000    0.8571    0.9231        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9459        37\n",
      "    macro avg     0.9333    0.9524    0.9373        37\n",
      " weighted avg     0.9568    0.9459    0.9469        37\n",
      "\n",
      "2025-05-30 00:33:11,644 - WARNING - ROC AUC computation failed for val: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n",
      "2025-05-30 00:33:11,674 - INFO - Epoch 22/25\n",
      "2025-05-30 00:33:11,674 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:33:13,355 - INFO - Training Loss: 0.6016, Accuracy: 0.8490\n",
      "2025-05-30 00:33:13,492 - INFO - Validation Loss: 0.4561, Accuracy: 0.9459\n",
      "2025-05-30 00:33:13,762 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_22.pth\n",
      "2025-05-30 00:33:13,792 - INFO - Epoch 23/25\n",
      "2025-05-30 00:33:13,792 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:33:15,687 - INFO - Training Loss: 0.5315, Accuracy: 0.9010\n",
      "2025-05-30 00:33:15,880 - INFO - Validation Loss: 0.4126, Accuracy: 0.9459\n",
      "2025-05-30 00:33:16,497 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_23.pth\n",
      "2025-05-30 00:33:16,542 - INFO - Epoch 24/25\n",
      "2025-05-30 00:33:16,542 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:33:18,778 - INFO - Training Loss: 0.5112, Accuracy: 0.8958\n",
      "2025-05-30 00:33:18,913 - INFO - Validation Loss: 0.3730, Accuracy: 0.9459\n",
      "2025-05-30 00:33:19,483 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_24.pth\n",
      "2025-05-30 00:33:19,513 - INFO - Epoch 25/25\n",
      "2025-05-30 00:33:19,513 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:33:21,136 - INFO - Training Loss: 0.4804, Accuracy: 0.8958\n",
      "2025-05-30 00:33:21,271 - INFO - Validation Loss: 0.3350, Accuracy: 0.9459\n",
      "2025-05-30 00:33:21,452 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\resnet50_epoch_25.pth\n",
      "2025-05-30 00:33:21,482 - INFO - Loading best model weights from epoch 25\n",
      "2025-05-30 00:33:22,471 - INFO - \n",
      "Test Classification Report - Epoch 25:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.5333    1.0000    0.6957         8\n",
      "         Sick     1.0000    0.5625    0.7200        16\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.8205        39\n",
      "    macro avg     0.8444    0.8542    0.8052        39\n",
      " weighted avg     0.9043    0.8205    0.8227        39\n",
      "\n",
      "2025-05-30 00:33:22,471 - WARNING - ROC AUC computation failed for test: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weights = compute_class_weights(train_df_balanced)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"resnet50\"\n",
    "model = get_model(model_name, num_classes, device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True, save_dir=save_dir)\n",
    "\n",
    "trained_model = train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    model_name_prefix=model_name,\n",
    "    class_weights=class_weights,\n",
    "    epochs=25,\n",
    "    device=device,\n",
    "    early_stopping=early_stopping,\n",
    "    save_dir=save_dir,\n",
    "    accum_steps=4,\n",
    "    class_names=['normal', 'Sick', 'Unknown_class']\n",
    ")\n",
    "\n",
    "compute_metrics(trained_model, test_loader, device, epoch=early_stopping.best_epoch + 1 or 25, \n",
    "                split_name=\"test\", save_dir=save_dir, class_names=['normal', 'Sick', 'Unknown_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f966a61b",
   "metadata": {},
   "source": [
    "# efficientnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f63497a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 00:34:16,438 - INFO - Class weights: tensor([1., 1., 1.], device='cuda:0')\n",
      "2025-05-30 00:34:16,438 - INFO - Loading model: efficientnet_b0 with 3 classes on cuda\n",
      "2025-05-30 00:34:16,716 - INFO - Model efficientnet_b0 loaded with 1280 input features to classifier\n",
      "2025-05-30 00:34:16,761 - INFO - Using mixed precision training: True\n",
      "2025-05-30 00:34:16,761 - INFO - Epoch 1/25\n",
      "2025-05-30 00:34:16,761 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:34:29,577 - INFO - Training Loss: 2.2120, Accuracy: 0.3177\n",
      "2025-05-30 00:34:30,705 - INFO - Validation Loss: 1.0942, Accuracy: 0.3514\n",
      "2025-05-30 00:34:30,829 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_1.pth\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\alira\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2025-05-30 00:34:32,151 - INFO - \n",
      "Val Classification Report - Epoch 1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.0000    0.0000    0.0000         8\n",
      "         Sick     0.3714    0.9286    0.5306        14\n",
      "Unknown_class     0.0000    0.0000    0.0000        15\n",
      "\n",
      "     accuracy                         0.3514        37\n",
      "    macro avg     0.1238    0.3095    0.1769        37\n",
      " weighted avg     0.1405    0.3514    0.2008        37\n",
      "\n",
      "2025-05-30 00:34:32,158 - INFO - Val ROC AUC: 0.6452\n",
      "2025-05-30 00:34:32,645 - INFO - Epoch 2/25\n",
      "2025-05-30 00:34:32,645 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:34:40,801 - INFO - Training Loss: 1.8445, Accuracy: 0.3177\n",
      "2025-05-30 00:34:41,689 - INFO - Validation Loss: 1.0849, Accuracy: 0.3514\n",
      "2025-05-30 00:34:41,781 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_2.pth\n",
      "2025-05-30 00:34:42,165 - INFO - Epoch 3/25\n",
      "2025-05-30 00:34:42,165 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:34:50,927 - INFO - Training Loss: 1.5860, Accuracy: 0.3802\n",
      "2025-05-30 00:34:51,724 - INFO - Validation Loss: 1.0725, Accuracy: 0.4595\n",
      "2025-05-30 00:34:51,829 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_3.pth\n",
      "2025-05-30 00:34:52,234 - INFO - Epoch 4/25\n",
      "2025-05-30 00:34:52,237 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:35:01,524 - INFO - Training Loss: 1.4266, Accuracy: 0.3333\n",
      "2025-05-30 00:35:02,301 - INFO - Validation Loss: 1.0588, Accuracy: 0.5135\n",
      "2025-05-30 00:35:02,436 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_4.pth\n",
      "2025-05-30 00:35:02,811 - INFO - Epoch 5/25\n",
      "2025-05-30 00:35:02,827 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:35:11,184 - INFO - Training Loss: 1.3215, Accuracy: 0.4635\n",
      "2025-05-30 00:35:11,922 - INFO - Validation Loss: 1.0435, Accuracy: 0.7027\n",
      "2025-05-30 00:35:12,012 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_5.pth\n",
      "2025-05-30 00:35:12,357 - INFO - Epoch 6/25\n",
      "2025-05-30 00:35:12,357 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:35:20,615 - INFO - Training Loss: 1.2556, Accuracy: 0.5000\n",
      "2025-05-30 00:35:21,709 - INFO - Validation Loss: 1.0258, Accuracy: 0.7838\n",
      "2025-05-30 00:35:21,802 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_6.pth\n",
      "2025-05-30 00:35:23,110 - INFO - \n",
      "Val Classification Report - Epoch 6:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.7000    0.8750    0.7778         8\n",
      "         Sick     0.6875    0.7857    0.7333        14\n",
      "Unknown_class     1.0000    0.7333    0.8462        15\n",
      "\n",
      "     accuracy                         0.7838        37\n",
      "    macro avg     0.7958    0.7980    0.7858        37\n",
      " weighted avg     0.8169    0.7838    0.7887        37\n",
      "\n",
      "2025-05-30 00:35:23,126 - INFO - Val ROC AUC: 0.9660\n",
      "2025-05-30 00:35:23,560 - INFO - Epoch 7/25\n",
      "2025-05-30 00:35:23,560 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:35:32,608 - INFO - Training Loss: 1.2059, Accuracy: 0.5677\n",
      "2025-05-30 00:35:33,224 - INFO - Validation Loss: 1.0089, Accuracy: 0.8378\n",
      "2025-05-30 00:35:33,345 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_7.pth\n",
      "2025-05-30 00:35:33,720 - INFO - Epoch 8/25\n",
      "2025-05-30 00:35:33,720 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:35:41,854 - INFO - Training Loss: 1.1571, Accuracy: 0.5781\n",
      "2025-05-30 00:35:42,963 - INFO - Validation Loss: 0.9920, Accuracy: 0.8649\n",
      "2025-05-30 00:35:43,073 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_8.pth\n",
      "2025-05-30 00:35:43,508 - INFO - Epoch 9/25\n",
      "2025-05-30 00:35:43,508 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:35:51,999 - INFO - Training Loss: 1.1377, Accuracy: 0.6042\n",
      "2025-05-30 00:35:53,097 - INFO - Validation Loss: 0.9737, Accuracy: 0.8919\n",
      "2025-05-30 00:35:53,187 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_9.pth\n",
      "2025-05-30 00:35:53,621 - INFO - Epoch 10/25\n",
      "2025-05-30 00:35:53,621 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:36:02,550 - INFO - Training Loss: 1.1008, Accuracy: 0.6719\n",
      "2025-05-30 00:36:03,647 - INFO - Validation Loss: 0.9526, Accuracy: 0.9189\n",
      "2025-05-30 00:36:03,738 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_10.pth\n",
      "2025-05-30 00:36:04,159 - INFO - Epoch 11/25\n",
      "2025-05-30 00:36:04,159 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:36:13,568 - INFO - Training Loss: 1.0759, Accuracy: 0.7083\n",
      "2025-05-30 00:36:14,661 - INFO - Validation Loss: 0.9317, Accuracy: 0.9189\n",
      "2025-05-30 00:36:14,757 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_11.pth\n",
      "2025-05-30 00:36:16,098 - INFO - \n",
      "Val Classification Report - Epoch 11:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.7273    1.0000    0.8421         8\n",
      "         Sick     1.0000    0.7857    0.8800        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9189        37\n",
      "    macro avg     0.9091    0.9286    0.9074        37\n",
      " weighted avg     0.9410    0.9189    0.9205        37\n",
      "\n",
      "2025-05-30 00:36:16,100 - INFO - Val ROC AUC: 0.9769\n",
      "2025-05-30 00:36:16,520 - INFO - Epoch 12/25\n",
      "2025-05-30 00:36:16,522 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:36:24,588 - INFO - Training Loss: 1.0486, Accuracy: 0.7396\n",
      "2025-05-30 00:36:25,675 - INFO - Validation Loss: 0.9081, Accuracy: 0.9189\n",
      "2025-05-30 00:36:25,771 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_12.pth\n",
      "2025-05-30 00:36:26,140 - INFO - Epoch 13/25\n",
      "2025-05-30 00:36:26,140 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:36:34,733 - INFO - Training Loss: 1.0137, Accuracy: 0.7552\n",
      "2025-05-30 00:36:35,421 - INFO - Validation Loss: 0.8847, Accuracy: 0.9459\n",
      "2025-05-30 00:36:35,512 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_13.pth\n",
      "2025-05-30 00:36:35,812 - INFO - Epoch 14/25\n",
      "2025-05-30 00:36:35,812 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:36:43,703 - INFO - Training Loss: 1.0057, Accuracy: 0.7708\n",
      "2025-05-30 00:36:44,792 - INFO - Validation Loss: 0.8586, Accuracy: 0.9459\n",
      "2025-05-30 00:36:44,873 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_14.pth\n",
      "2025-05-30 00:36:45,263 - INFO - Epoch 15/25\n",
      "2025-05-30 00:36:45,279 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:36:53,195 - INFO - Training Loss: 0.9861, Accuracy: 0.7344\n",
      "2025-05-30 00:36:54,264 - INFO - Validation Loss: 0.8302, Accuracy: 0.9459\n",
      "2025-05-30 00:36:54,352 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_15.pth\n",
      "2025-05-30 00:36:54,727 - INFO - Epoch 16/25\n",
      "2025-05-30 00:36:54,727 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:37:04,120 - INFO - Training Loss: 0.9567, Accuracy: 0.7604\n",
      "2025-05-30 00:37:05,205 - INFO - Validation Loss: 0.7999, Accuracy: 0.9459\n",
      "2025-05-30 00:37:05,317 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_16.pth\n",
      "2025-05-30 00:37:06,534 - INFO - \n",
      "Val Classification Report - Epoch 16:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.8000    1.0000    0.8889         8\n",
      "         Sick     1.0000    0.8571    0.9231        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9459        37\n",
      "    macro avg     0.9333    0.9524    0.9373        37\n",
      " weighted avg     0.9568    0.9459    0.9469        37\n",
      "\n",
      "2025-05-30 00:37:06,535 - INFO - Val ROC AUC: 0.9770\n",
      "2025-05-30 00:37:06,903 - INFO - Epoch 17/25\n",
      "2025-05-30 00:37:06,903 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:37:16,254 - INFO - Training Loss: 0.9255, Accuracy: 0.8021\n",
      "2025-05-30 00:37:17,235 - INFO - Validation Loss: 0.7716, Accuracy: 0.9459\n",
      "2025-05-30 00:37:17,361 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_17.pth\n",
      "2025-05-30 00:37:17,679 - INFO - Epoch 18/25\n",
      "2025-05-30 00:37:17,679 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:37:26,785 - INFO - Training Loss: 0.9056, Accuracy: 0.7656\n",
      "2025-05-30 00:37:27,482 - INFO - Validation Loss: 0.7428, Accuracy: 0.9459\n",
      "2025-05-30 00:37:27,616 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_18.pth\n",
      "2025-05-30 00:37:27,883 - INFO - Epoch 19/25\n",
      "2025-05-30 00:37:27,884 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:37:35,424 - INFO - Training Loss: 0.8700, Accuracy: 0.8333\n",
      "2025-05-30 00:37:35,980 - INFO - Validation Loss: 0.7105, Accuracy: 0.9459\n",
      "2025-05-30 00:37:36,072 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_19.pth\n",
      "2025-05-30 00:37:36,341 - INFO - Epoch 20/25\n",
      "2025-05-30 00:37:36,341 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:37:45,498 - INFO - Training Loss: 0.8442, Accuracy: 0.7865\n",
      "2025-05-30 00:37:46,591 - INFO - Validation Loss: 0.6775, Accuracy: 0.9459\n",
      "2025-05-30 00:37:46,670 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_20.pth\n",
      "2025-05-30 00:37:46,999 - INFO - Epoch 21/25\n",
      "2025-05-30 00:37:47,015 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:37:56,824 - INFO - Training Loss: 0.8068, Accuracy: 0.8229\n",
      "2025-05-30 00:37:57,908 - INFO - Validation Loss: 0.6422, Accuracy: 0.9459\n",
      "2025-05-30 00:37:57,984 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_21.pth\n",
      "2025-05-30 00:37:59,064 - INFO - \n",
      "Val Classification Report - Epoch 21:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.8000    1.0000    0.8889         8\n",
      "         Sick     1.0000    0.8571    0.9231        14\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.9459        37\n",
      "    macro avg     0.9333    0.9524    0.9373        37\n",
      " weighted avg     0.9568    0.9459    0.9469        37\n",
      "\n",
      "2025-05-30 00:37:59,079 - INFO - Val ROC AUC: 0.9821\n",
      "2025-05-30 00:37:59,425 - INFO - Epoch 22/25\n",
      "2025-05-30 00:37:59,425 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:38:08,752 - INFO - Training Loss: 0.7994, Accuracy: 0.7604\n",
      "2025-05-30 00:38:09,834 - INFO - Validation Loss: 0.6050, Accuracy: 0.9459\n",
      "2025-05-30 00:38:10,306 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_22.pth\n",
      "2025-05-30 00:38:10,667 - INFO - Epoch 23/25\n",
      "2025-05-30 00:38:10,667 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:38:19,552 - INFO - Training Loss: 0.7796, Accuracy: 0.7812\n",
      "2025-05-30 00:38:19,867 - INFO - Validation Loss: 0.5665, Accuracy: 0.9459\n",
      "2025-05-30 00:38:19,955 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_23.pth\n",
      "2025-05-30 00:38:20,296 - INFO - Epoch 24/25\n",
      "2025-05-30 00:38:20,296 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:38:26,203 - INFO - Training Loss: 0.7434, Accuracy: 0.7708\n",
      "2025-05-30 00:38:26,543 - INFO - Validation Loss: 0.5240, Accuracy: 0.9459\n",
      "2025-05-30 00:38:26,676 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_24.pth\n",
      "2025-05-30 00:38:26,982 - INFO - Epoch 25/25\n",
      "2025-05-30 00:38:26,989 - INFO - --------------------------------------------------\n",
      "2025-05-30 00:38:33,557 - INFO - Training Loss: 0.7098, Accuracy: 0.8125\n",
      "2025-05-30 00:38:33,863 - INFO - Validation Loss: 0.4913, Accuracy: 0.9459\n",
      "2025-05-30 00:38:34,016 - INFO - ✅ Best model weights saved to O:\\O drive\\AI\\my project\\medical image projects\\breast_termo\\plots\\efficientnet_b0_epoch_25.pth\n",
      "2025-05-30 00:38:34,301 - INFO - Loading best model weights from epoch 25\n",
      "2025-05-30 00:38:35,450 - INFO - \n",
      "Test Classification Report - Epoch 25:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       normal     0.5714    1.0000    0.7273         8\n",
      "         Sick     1.0000    0.6250    0.7692        16\n",
      "Unknown_class     1.0000    1.0000    1.0000        15\n",
      "\n",
      "     accuracy                         0.8462        39\n",
      "    macro avg     0.8571    0.8750    0.8322        39\n",
      " weighted avg     0.9121    0.8462    0.8494        39\n",
      "\n",
      "2025-05-30 00:38:35,456 - INFO - Test ROC AUC: 0.9654\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weights = compute_class_weights(train_df_balanced)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"efficientnet_b0\"\n",
    "model = get_model(model_name, num_classes, device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True, save_dir=save_dir)\n",
    "\n",
    "trained_model = train_and_validate(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    model_name_prefix=model_name,\n",
    "    class_weights=class_weights,\n",
    "    epochs=25,\n",
    "    device=device,\n",
    "    early_stopping=early_stopping,\n",
    "    save_dir=save_dir,\n",
    "    accum_steps=4,\n",
    "    class_names=['normal', 'Sick', 'Unknown_class']\n",
    ")\n",
    "\n",
    "compute_metrics(trained_model, test_loader, device, epoch=early_stopping.best_epoch + 1 or 25, \n",
    "                split_name=\"test\", save_dir=save_dir, class_names=['normal', 'Sick', 'Unknown_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d08ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
